{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>department</th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>recruitment_channel</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>is_promoted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65438</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_7</td>\n",
       "      <td>Master's &amp; above</td>\n",
       "      <td>f</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65141</td>\n",
       "      <td>Operations</td>\n",
       "      <td>region_22</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7513</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_19</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2542</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_23</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48945</td>\n",
       "      <td>Technology</td>\n",
       "      <td>region_26</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id         department     region         education gender  \\\n",
       "0        65438  Sales & Marketing   region_7  Master's & above      f   \n",
       "1        65141         Operations  region_22        Bachelor's      m   \n",
       "2         7513  Sales & Marketing  region_19        Bachelor's      m   \n",
       "3         2542  Sales & Marketing  region_23        Bachelor's      m   \n",
       "4        48945         Technology  region_26        Bachelor's      m   \n",
       "\n",
       "  recruitment_channel  no_of_trainings  age  previous_year_rating  \\\n",
       "0            sourcing                1   35                   5.0   \n",
       "1               other                1   30                   5.0   \n",
       "2            sourcing                1   34                   3.0   \n",
       "3               other                2   39                   1.0   \n",
       "4               other                1   45                   3.0   \n",
       "\n",
       "   length_of_service  KPIs_met >80%  awards_won?  avg_training_score  \\\n",
       "0                  8              1            0                  49   \n",
       "1                  4              0            0                  60   \n",
       "2                  7              0            0                  50   \n",
       "3                 10              0            0                  50   \n",
       "4                  2              0            0                  73   \n",
       "\n",
       "   is_promoted  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = ['avg_training_score', 'age', 'length_of_service', 'no_of_trainings']\n",
    "category = ['KPIs_met >80%', 'awards_won?' ,'previous_year_rating', 'department', 'region', 'education', 'gender', 'recruitment_channel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in category:\n",
    "    #train_data[i] = train_data[i].astype('category')\n",
    "    #test_data[i] = test_data[i].astype('category')\n",
    "\n",
    "#train_data['is_promoted'] = train_data['is_promoted'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employee_id                0\n",
       "department                 0\n",
       "region                     0\n",
       "education               2409\n",
       "gender                     0\n",
       "recruitment_channel        0\n",
       "no_of_trainings            0\n",
       "age                        0\n",
       "previous_year_rating    4124\n",
       "length_of_service          0\n",
       "KPIs_met >80%              0\n",
       "awards_won?                0\n",
       "avg_training_score         0\n",
       "is_promoted                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employee_id                0\n",
       "department                 0\n",
       "region                     0\n",
       "education               1034\n",
       "gender                     0\n",
       "recruitment_channel        0\n",
       "no_of_trainings            0\n",
       "age                        0\n",
       "previous_year_rating    1812\n",
       "length_of_service          0\n",
       "KPIs_met >80%              0\n",
       "awards_won?                0\n",
       "avg_training_score         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Null values\n",
    "#train_data['education'] = train_data['education'].cat.add_categories('No Degree')\n",
    "train_data['education'].fillna('No Degree',inplace = True)\n",
    "#test_data['education'] = test_data['education'].cat.add_categories('No Degree')\n",
    "test_data['education'].fillna('No Degree',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Null values\n",
    "#train_data['previous_year_rating'] = train_data['previous_year_rating'].cat.add_categories('-999')\n",
    "train_data['previous_year_rating'].fillna(-999,inplace = True)\n",
    "#test_data['previous_year_rating'] = test_data['previous_year_rating'].cat.add_categories('-999')\n",
    "test_data['previous_year_rating'].fillna(-999,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employee_id             0\n",
       "department              0\n",
       "region                  0\n",
       "education               0\n",
       "gender                  0\n",
       "recruitment_channel     0\n",
       "no_of_trainings         0\n",
       "age                     0\n",
       "previous_year_rating    0\n",
       "length_of_service       0\n",
       "KPIs_met >80%           0\n",
       "awards_won?             0\n",
       "avg_training_score      0\n",
       "is_promoted             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "#scaler = StandardScaler()\n",
    "#for i in numeric:\n",
    "#   train_data[i] = scaler.fit_transform(train_data[i].values.reshape(-1,1))\n",
    "#   test_data[i] = scaler.fit_transform(test_data[i].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>department</th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>recruitment_channel</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>is_promoted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65438</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_7</td>\n",
       "      <td>Master's &amp; above</td>\n",
       "      <td>f</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65141</td>\n",
       "      <td>Operations</td>\n",
       "      <td>region_22</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7513</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_19</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2542</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_23</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48945</td>\n",
       "      <td>Technology</td>\n",
       "      <td>region_26</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id         department     region         education gender  \\\n",
       "0        65438  Sales & Marketing   region_7  Master's & above      f   \n",
       "1        65141         Operations  region_22        Bachelor's      m   \n",
       "2         7513  Sales & Marketing  region_19        Bachelor's      m   \n",
       "3         2542  Sales & Marketing  region_23        Bachelor's      m   \n",
       "4        48945         Technology  region_26        Bachelor's      m   \n",
       "\n",
       "  recruitment_channel  no_of_trainings  age  previous_year_rating  \\\n",
       "0            sourcing                1   35                   5.0   \n",
       "1               other                1   30                   5.0   \n",
       "2            sourcing                1   34                   3.0   \n",
       "3               other                2   39                   1.0   \n",
       "4               other                1   45                   3.0   \n",
       "\n",
       "   length_of_service  KPIs_met >80%  awards_won?  avg_training_score  \\\n",
       "0                  8              1            0                  49   \n",
       "1                  4              0            0                  60   \n",
       "2                  7              0            0                  50   \n",
       "3                 10              0            0                  50   \n",
       "4                  2              0            0                  73   \n",
       "\n",
       "   is_promoted  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LabelEncoding\n",
    "category_encode = ['previous_year_rating', 'department', 'region', 'education', 'gender', 'recruitment_channel']\n",
    "le = LabelEncoder()\n",
    "for i in category_encode:\n",
    "    train_data[i] = le.fit_transform(train_data[i])\n",
    "    test_data[i] = le.transform(test_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping employee_id\n",
    "train_data.drop('employee_id', axis=1, inplace=True)\n",
    "Emp_ID = test_data['employee_id']\n",
    "test_data.drop('employee_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department</th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>recruitment_channel</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>is_promoted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   department  region  education  gender  recruitment_channel  \\\n",
       "0           7      31          2       0                    2   \n",
       "1           4      14          0       1                    0   \n",
       "2           7      10          0       1                    2   \n",
       "3           7      15          0       1                    0   \n",
       "4           8      18          0       1                    0   \n",
       "\n",
       "   no_of_trainings  age  previous_year_rating  length_of_service  \\\n",
       "0                1   35                     5                  8   \n",
       "1                1   30                     5                  4   \n",
       "2                1   34                     3                  7   \n",
       "3                2   39                     1                 10   \n",
       "4                1   45                     3                  2   \n",
       "\n",
       "   KPIs_met >80%  awards_won?  avg_training_score  is_promoted  \n",
       "0              1            0                  49            0  \n",
       "1              0            0                  60            0  \n",
       "2              0            0                  50            0  \n",
       "3              0            0                  50            0  \n",
       "4              0            0                  73            0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department</th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>recruitment_channel</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   department  region  education  gender  recruitment_channel  \\\n",
       "0           8      18          0       1                    2   \n",
       "1           2      28          0       0                    0   \n",
       "2           7       4          0       1                    0   \n",
       "3           5      11          0       0                    0   \n",
       "4           1      21          0       1                    2   \n",
       "\n",
       "   no_of_trainings  age  previous_year_rating  length_of_service  \\\n",
       "0                1   24                     0                  1   \n",
       "1                1   31                     3                  5   \n",
       "2                1   31                     1                  4   \n",
       "3                3   31                     2                  9   \n",
       "4                1   30                     4                  7   \n",
       "\n",
       "   KPIs_met >80%  awards_won?  avg_training_score  \n",
       "0              1            0                  77  \n",
       "1              0            0                  51  \n",
       "2              0            0                  47  \n",
       "3              0            0                  65  \n",
       "4              0            0                  61  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X = train_data.drop(\"is_promoted\",axis=1)\n",
    "Y = train_data[\"is_promoted\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.3, random_state=42, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'reg:logistic',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eval_metric'] = \"logloss\"\n",
    "num_boost_round = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-logloss:0.500662\n",
      "Will train until Test-logloss hasn't improved in 100 rounds.\n",
      "[1]\tTest-logloss:0.395891\n",
      "[2]\tTest-logloss:0.331692\n",
      "[3]\tTest-logloss:0.290062\n",
      "[4]\tTest-logloss:0.261097\n",
      "[5]\tTest-logloss:0.237996\n",
      "[6]\tTest-logloss:0.223808\n",
      "[7]\tTest-logloss:0.212815\n",
      "[8]\tTest-logloss:0.196251\n",
      "[9]\tTest-logloss:0.189495\n",
      "[10]\tTest-logloss:0.186129\n",
      "[11]\tTest-logloss:0.182823\n",
      "[12]\tTest-logloss:0.178448\n",
      "[13]\tTest-logloss:0.175482\n",
      "[14]\tTest-logloss:0.174165\n",
      "[15]\tTest-logloss:0.171899\n",
      "[16]\tTest-logloss:0.170394\n",
      "[17]\tTest-logloss:0.170108\n",
      "[18]\tTest-logloss:0.169769\n",
      "[19]\tTest-logloss:0.170164\n",
      "[20]\tTest-logloss:0.17001\n",
      "[21]\tTest-logloss:0.169973\n",
      "[22]\tTest-logloss:0.169484\n",
      "[23]\tTest-logloss:0.168731\n",
      "[24]\tTest-logloss:0.168805\n",
      "[25]\tTest-logloss:0.168713\n",
      "[26]\tTest-logloss:0.168752\n",
      "[27]\tTest-logloss:0.168819\n",
      "[28]\tTest-logloss:0.168841\n",
      "[29]\tTest-logloss:0.168999\n",
      "[30]\tTest-logloss:0.169023\n",
      "[31]\tTest-logloss:0.168339\n",
      "[32]\tTest-logloss:0.168252\n",
      "[33]\tTest-logloss:0.168023\n",
      "[34]\tTest-logloss:0.167987\n",
      "[35]\tTest-logloss:0.167958\n",
      "[36]\tTest-logloss:0.167435\n",
      "[37]\tTest-logloss:0.167609\n",
      "[38]\tTest-logloss:0.167665\n",
      "[39]\tTest-logloss:0.167747\n",
      "[40]\tTest-logloss:0.167809\n",
      "[41]\tTest-logloss:0.167807\n",
      "[42]\tTest-logloss:0.167871\n",
      "[43]\tTest-logloss:0.16771\n",
      "[44]\tTest-logloss:0.167575\n",
      "[45]\tTest-logloss:0.167636\n",
      "[46]\tTest-logloss:0.167602\n",
      "[47]\tTest-logloss:0.167457\n",
      "[48]\tTest-logloss:0.167288\n",
      "[49]\tTest-logloss:0.167192\n",
      "[50]\tTest-logloss:0.167323\n",
      "[51]\tTest-logloss:0.167419\n",
      "[52]\tTest-logloss:0.167624\n",
      "[53]\tTest-logloss:0.167668\n",
      "[54]\tTest-logloss:0.167743\n",
      "[55]\tTest-logloss:0.167762\n",
      "[56]\tTest-logloss:0.167803\n",
      "[57]\tTest-logloss:0.167901\n",
      "[58]\tTest-logloss:0.167933\n",
      "[59]\tTest-logloss:0.168016\n",
      "[60]\tTest-logloss:0.168085\n",
      "[61]\tTest-logloss:0.167955\n",
      "[62]\tTest-logloss:0.168148\n",
      "[63]\tTest-logloss:0.168212\n",
      "[64]\tTest-logloss:0.168175\n",
      "[65]\tTest-logloss:0.16828\n",
      "[66]\tTest-logloss:0.168376\n",
      "[67]\tTest-logloss:0.168409\n",
      "[68]\tTest-logloss:0.168655\n",
      "[69]\tTest-logloss:0.168781\n",
      "[70]\tTest-logloss:0.168756\n",
      "[71]\tTest-logloss:0.168965\n",
      "[72]\tTest-logloss:0.169129\n",
      "[73]\tTest-logloss:0.169144\n",
      "[74]\tTest-logloss:0.169164\n",
      "[75]\tTest-logloss:0.169318\n",
      "[76]\tTest-logloss:0.169303\n",
      "[77]\tTest-logloss:0.169504\n",
      "[78]\tTest-logloss:0.169541\n",
      "[79]\tTest-logloss:0.169753\n",
      "[80]\tTest-logloss:0.169822\n",
      "[81]\tTest-logloss:0.16987\n",
      "[82]\tTest-logloss:0.170084\n",
      "[83]\tTest-logloss:0.16985\n",
      "[84]\tTest-logloss:0.170051\n",
      "[85]\tTest-logloss:0.170155\n",
      "[86]\tTest-logloss:0.170331\n",
      "[87]\tTest-logloss:0.170354\n",
      "[88]\tTest-logloss:0.170472\n",
      "[89]\tTest-logloss:0.170439\n",
      "[90]\tTest-logloss:0.170461\n",
      "[91]\tTest-logloss:0.170538\n",
      "[92]\tTest-logloss:0.170886\n",
      "[93]\tTest-logloss:0.170995\n",
      "[94]\tTest-logloss:0.171302\n",
      "[95]\tTest-logloss:0.171446\n",
      "[96]\tTest-logloss:0.171592\n",
      "[97]\tTest-logloss:0.171738\n",
      "[98]\tTest-logloss:0.171818\n",
      "[99]\tTest-logloss:0.171979\n",
      "[100]\tTest-logloss:0.172027\n",
      "[101]\tTest-logloss:0.172084\n",
      "[102]\tTest-logloss:0.172103\n",
      "[103]\tTest-logloss:0.172105\n",
      "[104]\tTest-logloss:0.172185\n",
      "[105]\tTest-logloss:0.172382\n",
      "[106]\tTest-logloss:0.172455\n",
      "[107]\tTest-logloss:0.172611\n",
      "[108]\tTest-logloss:0.172857\n",
      "[109]\tTest-logloss:0.173151\n",
      "[110]\tTest-logloss:0.173204\n",
      "[111]\tTest-logloss:0.173341\n",
      "[112]\tTest-logloss:0.173326\n",
      "[113]\tTest-logloss:0.173381\n",
      "[114]\tTest-logloss:0.173433\n",
      "[115]\tTest-logloss:0.173644\n",
      "[116]\tTest-logloss:0.173713\n",
      "[117]\tTest-logloss:0.173771\n",
      "[118]\tTest-logloss:0.173768\n",
      "[119]\tTest-logloss:0.173769\n",
      "[120]\tTest-logloss:0.173875\n",
      "[121]\tTest-logloss:0.17393\n",
      "[122]\tTest-logloss:0.173949\n",
      "[123]\tTest-logloss:0.174006\n",
      "[124]\tTest-logloss:0.174165\n",
      "[125]\tTest-logloss:0.174333\n",
      "[126]\tTest-logloss:0.174368\n",
      "[127]\tTest-logloss:0.174457\n",
      "[128]\tTest-logloss:0.174741\n",
      "[129]\tTest-logloss:0.174854\n",
      "[130]\tTest-logloss:0.175088\n",
      "[131]\tTest-logloss:0.175115\n",
      "[132]\tTest-logloss:0.175306\n",
      "[133]\tTest-logloss:0.17547\n",
      "[134]\tTest-logloss:0.175624\n",
      "[135]\tTest-logloss:0.175685\n",
      "[136]\tTest-logloss:0.175808\n",
      "[137]\tTest-logloss:0.176135\n",
      "[138]\tTest-logloss:0.176153\n",
      "[139]\tTest-logloss:0.176269\n",
      "[140]\tTest-logloss:0.176339\n",
      "[141]\tTest-logloss:0.176375\n",
      "[142]\tTest-logloss:0.176692\n",
      "[143]\tTest-logloss:0.176748\n",
      "[144]\tTest-logloss:0.176787\n",
      "[145]\tTest-logloss:0.177009\n",
      "[146]\tTest-logloss:0.177032\n",
      "[147]\tTest-logloss:0.177298\n",
      "[148]\tTest-logloss:0.177475\n",
      "[149]\tTest-logloss:0.177527\n",
      "Stopping. Best iteration:\n",
      "[49]\tTest-logloss:0.167192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logloss: 0.17 with 50 rounds\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Logloss: {:.2f} with {} rounds\".format(\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_data.drop(\"is_promoted\",axis=1), label=train_data['is_promoted'])\n",
    "dtest = xgb.DMatrix(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-logloss-mean</th>\n",
       "      <th>train-logloss-std</th>\n",
       "      <th>test-logloss-mean</th>\n",
       "      <th>test-logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.499990</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.500470</td>\n",
       "      <td>0.001672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.394219</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>0.395237</td>\n",
       "      <td>0.002296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.329250</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.330778</td>\n",
       "      <td>0.003027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.286508</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.003807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.257891</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.260380</td>\n",
       "      <td>0.004344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.237870</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>0.240920</td>\n",
       "      <td>0.004661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.222541</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>0.226023</td>\n",
       "      <td>0.005122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.208634</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>0.212476</td>\n",
       "      <td>0.005361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.194480</td>\n",
       "      <td>0.004430</td>\n",
       "      <td>0.199027</td>\n",
       "      <td>0.003899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.184804</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.189708</td>\n",
       "      <td>0.006010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.179402</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.184616</td>\n",
       "      <td>0.005898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.174441</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>0.180090</td>\n",
       "      <td>0.006107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.171187</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.177266</td>\n",
       "      <td>0.005100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.168045</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.174752</td>\n",
       "      <td>0.005632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.165486</td>\n",
       "      <td>0.002070</td>\n",
       "      <td>0.172685</td>\n",
       "      <td>0.005643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.164001</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.171741</td>\n",
       "      <td>0.005672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.162490</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.170701</td>\n",
       "      <td>0.005617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.161252</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.169884</td>\n",
       "      <td>0.005776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.160192</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.169468</td>\n",
       "      <td>0.006047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.159171</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.168877</td>\n",
       "      <td>0.005844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.158309</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.168534</td>\n",
       "      <td>0.005918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.157211</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.168081</td>\n",
       "      <td>0.006109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.156609</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.167862</td>\n",
       "      <td>0.006024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.155715</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.167495</td>\n",
       "      <td>0.006079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.155095</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>0.167278</td>\n",
       "      <td>0.005972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.154280</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>0.167072</td>\n",
       "      <td>0.005902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.153057</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.166409</td>\n",
       "      <td>0.005777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.152467</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.166362</td>\n",
       "      <td>0.005824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.151577</td>\n",
       "      <td>0.001836</td>\n",
       "      <td>0.166030</td>\n",
       "      <td>0.005664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.150606</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.165784</td>\n",
       "      <td>0.005487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.149851</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.165710</td>\n",
       "      <td>0.005420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.149322</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.165613</td>\n",
       "      <td>0.005364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.148531</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.165302</td>\n",
       "      <td>0.005789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-logloss-mean  train-logloss-std  test-logloss-mean  test-logloss-std\n",
       "0             0.499990           0.000445           0.500470          0.001672\n",
       "1             0.394219           0.001290           0.395237          0.002296\n",
       "2             0.329250           0.001625           0.330778          0.003027\n",
       "3             0.286508           0.001566           0.288462          0.003807\n",
       "4             0.257891           0.001436           0.260380          0.004344\n",
       "5             0.237870           0.001684           0.240920          0.004661\n",
       "6             0.222541           0.001628           0.226023          0.005122\n",
       "7             0.208634           0.001345           0.212476          0.005361\n",
       "8             0.194480           0.004430           0.199027          0.003899\n",
       "9             0.184804           0.001803           0.189708          0.006010\n",
       "10            0.179402           0.002304           0.184616          0.005898\n",
       "11            0.174441           0.002099           0.180090          0.006107\n",
       "12            0.171187           0.002525           0.177266          0.005100\n",
       "13            0.168045           0.002065           0.174752          0.005632\n",
       "14            0.165486           0.002070           0.172685          0.005643\n",
       "15            0.164001           0.001961           0.171741          0.005672\n",
       "16            0.162490           0.001961           0.170701          0.005617\n",
       "17            0.161252           0.001670           0.169884          0.005776\n",
       "18            0.160192           0.001647           0.169468          0.006047\n",
       "19            0.159171           0.001859           0.168877          0.005844\n",
       "20            0.158309           0.001746           0.168534          0.005918\n",
       "21            0.157211           0.001438           0.168081          0.006109\n",
       "22            0.156609           0.001603           0.167862          0.006024\n",
       "23            0.155715           0.001509           0.167495          0.006079\n",
       "24            0.155095           0.001823           0.167278          0.005972\n",
       "25            0.154280           0.001910           0.167072          0.005902\n",
       "26            0.153057           0.002052           0.166409          0.005777\n",
       "27            0.152467           0.001941           0.166362          0.005824\n",
       "28            0.151577           0.001836           0.166030          0.005664\n",
       "29            0.150606           0.001993           0.165784          0.005487\n",
       "30            0.149851           0.002193           0.165710          0.005420\n",
       "31            0.149322           0.002280           0.165613          0.005364\n",
       "32            0.148531           0.001801           0.165302          0.005789"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'logloss'},\n",
    "    early_stopping_rounds=100\n",
    ")\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1653024"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test-logloss-mean'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can try wider intervals with a larger step between\n",
    "# each value and then narrow it down. Here after several\n",
    "# iteration I found that the optimal value was in the\n",
    "# following ranges.\n",
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(7,10)\n",
    "    for min_child_weight in range(5,8)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=7, min_child_weight=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: \n",
      "The current behaviour of 'Series.argmin' is deprecated, use 'idxmin'\n",
      "instead.\n",
      "The behavior of 'argmin' will be corrected to return the positional\n",
      "minimum in the future. For now, use 'series.values.argmin' or\n",
      "'np.argmin(np.array(values))' to get the position of the minimum\n",
      "row.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLogLoss 0.16601059999999998 for 44 rounds\n",
      "CV with max_depth=7, min_child_weight=6\n",
      "\tLogLoss 0.16612900000000003 for 43 rounds\n",
      "CV with max_depth=7, min_child_weight=7\n",
      "\tLogLoss 0.1661516 for 38 rounds\n",
      "CV with max_depth=8, min_child_weight=5\n",
      "\tLogLoss 0.1667286 for 27 rounds\n",
      "CV with max_depth=8, min_child_weight=6\n",
      "\tLogLoss 0.1668026 for 29 rounds\n",
      "CV with max_depth=8, min_child_weight=7\n",
      "\tLogLoss 0.1663246 for 29 rounds\n",
      "CV with max_depth=9, min_child_weight=5\n",
      "\tLogLoss 0.1675464 for 30 rounds\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "\tLogLoss 0.167476 for 24 rounds\n",
      "CV with max_depth=9, min_child_weight=7\n",
      "\tLogLoss 0.167218 for 32 rounds\n",
      "Best params: 7, 5, logloss: 0.16601059999999998\n"
     ]
    }
   ],
   "source": [
    "# Define initial best params and Logloss\n",
    "min_logloss = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'logloss'},\n",
    "        early_stopping_rounds=100\n",
    "    )\n",
    "    # Update best MAE\n",
    "    mean_logloss = cv_results['test-logloss-mean'].min()\n",
    "    boost_rounds = cv_results['test-logloss-mean'].argmin()\n",
    "    print(\"\\tLogLoss {} for {} rounds\".format(mean_logloss, boost_rounds))\n",
    "    if mean_logloss < min_logloss:\n",
    "        min_logloss = mean_logloss\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, logloss: {}\".format(best_params[0], best_params[1], min_logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = best_params[0]\n",
    "params['min_child_weight'] = best_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: \n",
      "The current behaviour of 'Series.argmin' is deprecated, use 'idxmin'\n",
      "instead.\n",
      "The behavior of 'argmin' will be corrected to return the positional\n",
      "minimum in the future. For now, use 'series.values.argmin' or\n",
      "'np.argmin(np.array(values))' to get the position of the minimum\n",
      "row.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMAE 0.16601059999999998 for 44 rounds\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "\tMAE 0.1660008 for 37 rounds\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "\tMAE 0.1659586 for 34 rounds\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "\tMAE 0.16546840000000002 for 45 rounds\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "\tMAE 0.1665584 for 33 rounds\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "\tMAE 0.1660868 for 37 rounds\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "\tMAE 0.16608920000000002 for 38 rounds\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "\tMAE 0.16677799999999998 for 44 rounds\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "\tMAE 0.1670002 for 28 rounds\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "\tMAE 0.1665454 for 34 rounds\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "\tMAE 0.16770559999999998 for 34 rounds\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "\tMAE 0.167497 for 41 rounds\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "\tMAE 0.16831420000000002 for 29 rounds\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "\tMAE 0.16879899999999998 for 27 rounds\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "\tMAE 0.16880820000000002 for 35 rounds\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "\tMAE 0.1689126 for 42 rounds\n",
      "Best params: 1.0, 0.7, Logloss: 0.16546840000000002\n"
     ]
    }
   ],
   "source": [
    "min_logloss = float(\"Inf\")\n",
    "best_params = None\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'logloss'},\n",
    "        early_stopping_rounds=100\n",
    "    )\n",
    "    # Update best score\n",
    "    mean_logloss = cv_results['test-logloss-mean'].min()\n",
    "    boost_rounds = cv_results['test-logloss-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_logloss, boost_rounds))\n",
    "    if mean_logloss < min_logloss:\n",
    "        min_logloss = mean_logloss\n",
    "        best_params = (subsample,colsample)\n",
    "print(\"Best params: {}, {}, Logloss: {}\".format(best_params[0], best_params[1], min_logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['subsample'] = best_params[0]\n",
    "params['colsample_bytree'] = best_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "CV with eta=0.3\n",
      "Wall time: 6.62 s\n",
      "\tLogloss 0.16546840000000002 for 45 rounds\n",
      "\n",
      "CV with eta=0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: \n",
      "The current behaviour of 'Series.argmin' is deprecated, use 'idxmin'\n",
      "instead.\n",
      "The behavior of 'argmin' will be corrected to return the positional\n",
      "minimum in the future. For now, use 'series.values.argmin' or\n",
      "'np.argmin(np.array(values))' to get the position of the minimum\n",
      "row.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.64 s\n",
      "\tLogloss 0.1651418 for 73 rounds\n",
      "\n",
      "CV with eta=0.1\n",
      "Wall time: 11.5 s\n",
      "\tLogloss 0.164234 for 150 rounds\n",
      "\n",
      "CV with eta=0.05\n",
      "Wall time: 19 s\n",
      "\tLogloss 0.16397599999999998 for 324 rounds\n",
      "\n",
      "CV with eta=0.01\n",
      "Wall time: 45.1 s\n",
      "\tLogloss 0.1652712 for 998 rounds\n",
      "\n",
      "CV with eta=0.005\n",
      "Wall time: 46.6 s\n",
      "\tLogloss 0.17917280000000002 for 998 rounds\n",
      "\n",
      "Best params: 0.05, Logloss: 0.16397599999999998\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# This can take some time…\n",
    "min_logloss = float(\"Inf\")\n",
    "best_params = None\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "    # Run and time CV\n",
    "    %time cv_results = xgb.cv(params,dtrain,num_boost_round=num_boost_round,seed=42,nfold=5,metrics=['logloss'],early_stopping_rounds=100)\n",
    "    # Update best score\n",
    "    mean_logloss = cv_results['test-logloss-mean'].min()\n",
    "    boost_rounds = cv_results['test-logloss-mean'].argmin()\n",
    "    print(\"\\tLogloss {} for {} rounds\\n\".format(mean_logloss, boost_rounds))\n",
    "    if mean_logloss < min_logloss:\n",
    "        min_logloss = mean_logloss\n",
    "        best_params = eta\n",
    "        \n",
    "print(\"Best params: {}, Logloss: {}\".format(best_params, min_logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eta'] = best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7,\n",
       " 'min_child_weight': 5,\n",
       " 'eta': 0.05,\n",
       " 'subsample': 1.0,\n",
       " 'colsample_bytree': 0.7,\n",
       " 'objective': 'reg:logistic',\n",
       " 'eval_metric': 'logloss'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-logloss:0.656391\n",
      "Will train until Test-logloss hasn't improved in 100 rounds.\n",
      "[1]\tTest-logloss:0.62266\n",
      "[2]\tTest-logloss:0.592491\n",
      "[3]\tTest-logloss:0.566279\n",
      "[4]\tTest-logloss:0.541319\n",
      "[5]\tTest-logloss:0.517355\n",
      "[6]\tTest-logloss:0.497296\n",
      "[7]\tTest-logloss:0.47703\n",
      "[8]\tTest-logloss:0.457576\n",
      "[9]\tTest-logloss:0.44036\n",
      "[10]\tTest-logloss:0.424155\n",
      "[11]\tTest-logloss:0.409756\n",
      "[12]\tTest-logloss:0.395933\n",
      "[13]\tTest-logloss:0.383968\n",
      "[14]\tTest-logloss:0.372081\n",
      "[15]\tTest-logloss:0.361508\n",
      "[16]\tTest-logloss:0.351987\n",
      "[17]\tTest-logloss:0.342684\n",
      "[18]\tTest-logloss:0.333722\n",
      "[19]\tTest-logloss:0.326012\n",
      "[20]\tTest-logloss:0.31803\n",
      "[21]\tTest-logloss:0.311247\n",
      "[22]\tTest-logloss:0.304797\n",
      "[23]\tTest-logloss:0.29856\n",
      "[24]\tTest-logloss:0.293126\n",
      "[25]\tTest-logloss:0.288005\n",
      "[26]\tTest-logloss:0.283531\n",
      "[27]\tTest-logloss:0.277734\n",
      "[28]\tTest-logloss:0.273168\n",
      "[29]\tTest-logloss:0.268592\n",
      "[30]\tTest-logloss:0.264889\n",
      "[31]\tTest-logloss:0.261355\n",
      "[32]\tTest-logloss:0.257951\n",
      "[33]\tTest-logloss:0.25495\n",
      "[34]\tTest-logloss:0.251481\n",
      "[35]\tTest-logloss:0.247854\n",
      "[36]\tTest-logloss:0.244185\n",
      "[37]\tTest-logloss:0.241746\n",
      "[38]\tTest-logloss:0.239765\n",
      "[39]\tTest-logloss:0.237821\n",
      "[40]\tTest-logloss:0.234775\n",
      "[41]\tTest-logloss:0.232854\n",
      "[42]\tTest-logloss:0.2307\n",
      "[43]\tTest-logloss:0.228557\n",
      "[44]\tTest-logloss:0.225315\n",
      "[45]\tTest-logloss:0.222919\n",
      "[46]\tTest-logloss:0.220624\n",
      "[47]\tTest-logloss:0.219027\n",
      "[48]\tTest-logloss:0.217433\n",
      "[49]\tTest-logloss:0.216552\n",
      "[50]\tTest-logloss:0.215753\n",
      "[51]\tTest-logloss:0.215012\n",
      "[52]\tTest-logloss:0.21322\n",
      "[53]\tTest-logloss:0.211566\n",
      "[54]\tTest-logloss:0.210467\n",
      "[55]\tTest-logloss:0.20875\n",
      "[56]\tTest-logloss:0.207789\n",
      "[57]\tTest-logloss:0.206888\n",
      "[58]\tTest-logloss:0.205416\n",
      "[59]\tTest-logloss:0.203948\n",
      "[60]\tTest-logloss:0.202588\n",
      "[61]\tTest-logloss:0.20189\n",
      "[62]\tTest-logloss:0.200676\n",
      "[63]\tTest-logloss:0.198849\n",
      "[64]\tTest-logloss:0.197151\n",
      "[65]\tTest-logloss:0.196044\n",
      "[66]\tTest-logloss:0.195527\n",
      "[67]\tTest-logloss:0.194038\n",
      "[68]\tTest-logloss:0.193156\n",
      "[69]\tTest-logloss:0.192491\n",
      "[70]\tTest-logloss:0.191899\n",
      "[71]\tTest-logloss:0.19133\n",
      "[72]\tTest-logloss:0.191181\n",
      "[73]\tTest-logloss:0.190414\n",
      "[74]\tTest-logloss:0.189695\n",
      "[75]\tTest-logloss:0.188868\n",
      "[76]\tTest-logloss:0.187722\n",
      "[77]\tTest-logloss:0.186579\n",
      "[78]\tTest-logloss:0.1863\n",
      "[79]\tTest-logloss:0.186204\n",
      "[80]\tTest-logloss:0.185926\n",
      "[81]\tTest-logloss:0.185676\n",
      "[82]\tTest-logloss:0.18514\n",
      "[83]\tTest-logloss:0.185084\n",
      "[84]\tTest-logloss:0.184717\n",
      "[85]\tTest-logloss:0.184506\n",
      "[86]\tTest-logloss:0.183567\n",
      "[87]\tTest-logloss:0.183551\n",
      "[88]\tTest-logloss:0.182953\n",
      "[89]\tTest-logloss:0.182709\n",
      "[90]\tTest-logloss:0.181882\n",
      "[91]\tTest-logloss:0.181736\n",
      "[92]\tTest-logloss:0.181371\n",
      "[93]\tTest-logloss:0.181155\n",
      "[94]\tTest-logloss:0.180996\n",
      "[95]\tTest-logloss:0.180653\n",
      "[96]\tTest-logloss:0.180532\n",
      "[97]\tTest-logloss:0.179997\n",
      "[98]\tTest-logloss:0.179822\n",
      "[99]\tTest-logloss:0.179731\n",
      "[100]\tTest-logloss:0.179077\n",
      "[101]\tTest-logloss:0.178493\n",
      "[102]\tTest-logloss:0.177919\n",
      "[103]\tTest-logloss:0.177646\n",
      "[104]\tTest-logloss:0.177158\n",
      "[105]\tTest-logloss:0.177002\n",
      "[106]\tTest-logloss:0.176555\n",
      "[107]\tTest-logloss:0.176051\n",
      "[108]\tTest-logloss:0.17605\n",
      "[109]\tTest-logloss:0.175954\n",
      "[110]\tTest-logloss:0.175379\n",
      "[111]\tTest-logloss:0.174899\n",
      "[112]\tTest-logloss:0.174738\n",
      "[113]\tTest-logloss:0.174628\n",
      "[114]\tTest-logloss:0.174161\n",
      "[115]\tTest-logloss:0.174102\n",
      "[116]\tTest-logloss:0.174088\n",
      "[117]\tTest-logloss:0.174054\n",
      "[118]\tTest-logloss:0.173619\n",
      "[119]\tTest-logloss:0.173536\n",
      "[120]\tTest-logloss:0.173482\n",
      "[121]\tTest-logloss:0.173422\n",
      "[122]\tTest-logloss:0.173352\n",
      "[123]\tTest-logloss:0.172947\n",
      "[124]\tTest-logloss:0.172861\n",
      "[125]\tTest-logloss:0.172504\n",
      "[126]\tTest-logloss:0.172491\n",
      "[127]\tTest-logloss:0.172415\n",
      "[128]\tTest-logloss:0.172186\n",
      "[129]\tTest-logloss:0.17214\n",
      "[130]\tTest-logloss:0.171954\n",
      "[131]\tTest-logloss:0.171957\n",
      "[132]\tTest-logloss:0.17163\n",
      "[133]\tTest-logloss:0.171635\n",
      "[134]\tTest-logloss:0.171631\n",
      "[135]\tTest-logloss:0.171322\n",
      "[136]\tTest-logloss:0.171267\n",
      "[137]\tTest-logloss:0.171247\n",
      "[138]\tTest-logloss:0.171223\n",
      "[139]\tTest-logloss:0.171144\n",
      "[140]\tTest-logloss:0.171005\n",
      "[141]\tTest-logloss:0.170981\n",
      "[142]\tTest-logloss:0.170964\n",
      "[143]\tTest-logloss:0.170921\n",
      "[144]\tTest-logloss:0.170651\n",
      "[145]\tTest-logloss:0.170415\n",
      "[146]\tTest-logloss:0.170154\n",
      "[147]\tTest-logloss:0.170004\n",
      "[148]\tTest-logloss:0.169914\n",
      "[149]\tTest-logloss:0.169878\n",
      "[150]\tTest-logloss:0.169869\n",
      "[151]\tTest-logloss:0.169856\n",
      "[152]\tTest-logloss:0.169832\n",
      "[153]\tTest-logloss:0.169621\n",
      "[154]\tTest-logloss:0.169594\n",
      "[155]\tTest-logloss:0.169614\n",
      "[156]\tTest-logloss:0.169631\n",
      "[157]\tTest-logloss:0.169431\n",
      "[158]\tTest-logloss:0.169414\n",
      "[159]\tTest-logloss:0.169403\n",
      "[160]\tTest-logloss:0.169395\n",
      "[161]\tTest-logloss:0.169382\n",
      "[162]\tTest-logloss:0.169285\n",
      "[163]\tTest-logloss:0.169086\n",
      "[164]\tTest-logloss:0.168922\n",
      "[165]\tTest-logloss:0.168884\n",
      "[166]\tTest-logloss:0.168737\n",
      "[167]\tTest-logloss:0.168742\n",
      "[168]\tTest-logloss:0.168732\n",
      "[169]\tTest-logloss:0.168739\n",
      "[170]\tTest-logloss:0.168678\n",
      "[171]\tTest-logloss:0.168673\n",
      "[172]\tTest-logloss:0.168628\n",
      "[173]\tTest-logloss:0.168471\n",
      "[174]\tTest-logloss:0.168494\n",
      "[175]\tTest-logloss:0.168427\n",
      "[176]\tTest-logloss:0.16837\n",
      "[177]\tTest-logloss:0.168374\n",
      "[178]\tTest-logloss:0.168267\n",
      "[179]\tTest-logloss:0.168249\n",
      "[180]\tTest-logloss:0.168183\n",
      "[181]\tTest-logloss:0.16817\n",
      "[182]\tTest-logloss:0.168171\n",
      "[183]\tTest-logloss:0.168171\n",
      "[184]\tTest-logloss:0.16808\n",
      "[185]\tTest-logloss:0.168065\n",
      "[186]\tTest-logloss:0.168078\n",
      "[187]\tTest-logloss:0.167961\n",
      "[188]\tTest-logloss:0.167955\n",
      "[189]\tTest-logloss:0.167952\n",
      "[190]\tTest-logloss:0.167946\n",
      "[191]\tTest-logloss:0.167928\n",
      "[192]\tTest-logloss:0.167929\n",
      "[193]\tTest-logloss:0.167937\n",
      "[194]\tTest-logloss:0.16779\n",
      "[195]\tTest-logloss:0.16779\n",
      "[196]\tTest-logloss:0.167822\n",
      "[197]\tTest-logloss:0.167812\n",
      "[198]\tTest-logloss:0.167812\n",
      "[199]\tTest-logloss:0.167718\n",
      "[200]\tTest-logloss:0.167717\n",
      "[201]\tTest-logloss:0.167696\n",
      "[202]\tTest-logloss:0.167704\n",
      "[203]\tTest-logloss:0.167727\n",
      "[204]\tTest-logloss:0.167652\n",
      "[205]\tTest-logloss:0.167587\n",
      "[206]\tTest-logloss:0.167607\n",
      "[207]\tTest-logloss:0.167618\n",
      "[208]\tTest-logloss:0.167492\n",
      "[209]\tTest-logloss:0.167483\n",
      "[210]\tTest-logloss:0.167402\n",
      "[211]\tTest-logloss:0.167378\n",
      "[212]\tTest-logloss:0.16732\n",
      "[213]\tTest-logloss:0.167333\n",
      "[214]\tTest-logloss:0.167327\n",
      "[215]\tTest-logloss:0.167231\n",
      "[216]\tTest-logloss:0.167224\n",
      "[217]\tTest-logloss:0.167232\n",
      "[218]\tTest-logloss:0.167219\n",
      "[219]\tTest-logloss:0.167141\n",
      "[220]\tTest-logloss:0.167173\n",
      "[221]\tTest-logloss:0.167163\n",
      "[222]\tTest-logloss:0.167167\n",
      "[223]\tTest-logloss:0.167155\n",
      "[224]\tTest-logloss:0.167175\n",
      "[225]\tTest-logloss:0.167155\n",
      "[226]\tTest-logloss:0.167171\n",
      "[227]\tTest-logloss:0.167189\n",
      "[228]\tTest-logloss:0.167199\n",
      "[229]\tTest-logloss:0.167189\n",
      "[230]\tTest-logloss:0.167097\n",
      "[231]\tTest-logloss:0.16709\n",
      "[232]\tTest-logloss:0.167118\n",
      "[233]\tTest-logloss:0.16714\n",
      "[234]\tTest-logloss:0.16703\n",
      "[235]\tTest-logloss:0.16705\n",
      "[236]\tTest-logloss:0.167058\n",
      "[237]\tTest-logloss:0.167123\n",
      "[238]\tTest-logloss:0.167131\n",
      "[239]\tTest-logloss:0.167143\n",
      "[240]\tTest-logloss:0.167073\n",
      "[241]\tTest-logloss:0.167083\n",
      "[242]\tTest-logloss:0.167077\n",
      "[243]\tTest-logloss:0.167084\n",
      "[244]\tTest-logloss:0.167094\n",
      "[245]\tTest-logloss:0.167056\n",
      "[246]\tTest-logloss:0.167065\n",
      "[247]\tTest-logloss:0.16706\n",
      "[248]\tTest-logloss:0.167056\n",
      "[249]\tTest-logloss:0.16707\n",
      "[250]\tTest-logloss:0.16707\n",
      "[251]\tTest-logloss:0.167072\n",
      "[252]\tTest-logloss:0.167092\n",
      "[253]\tTest-logloss:0.167094\n",
      "[254]\tTest-logloss:0.167101\n",
      "[255]\tTest-logloss:0.167056\n",
      "[256]\tTest-logloss:0.167038\n",
      "[257]\tTest-logloss:0.16705\n",
      "[258]\tTest-logloss:0.167037\n",
      "[259]\tTest-logloss:0.167016\n",
      "[260]\tTest-logloss:0.167019\n",
      "[261]\tTest-logloss:0.166961\n",
      "[262]\tTest-logloss:0.166974\n",
      "[263]\tTest-logloss:0.166974\n",
      "[264]\tTest-logloss:0.166934\n",
      "[265]\tTest-logloss:0.166961\n",
      "[266]\tTest-logloss:0.166926\n",
      "[267]\tTest-logloss:0.166933\n",
      "[268]\tTest-logloss:0.16695\n",
      "[269]\tTest-logloss:0.166971\n",
      "[270]\tTest-logloss:0.166962\n",
      "[271]\tTest-logloss:0.166961\n",
      "[272]\tTest-logloss:0.166997\n",
      "[273]\tTest-logloss:0.166993\n",
      "[274]\tTest-logloss:0.167003\n",
      "[275]\tTest-logloss:0.167011\n",
      "[276]\tTest-logloss:0.16701\n",
      "[277]\tTest-logloss:0.167017\n",
      "[278]\tTest-logloss:0.167033\n",
      "[279]\tTest-logloss:0.167033\n",
      "[280]\tTest-logloss:0.167051\n",
      "[281]\tTest-logloss:0.166998\n",
      "[282]\tTest-logloss:0.167032\n",
      "[283]\tTest-logloss:0.166988\n",
      "[284]\tTest-logloss:0.167\n",
      "[285]\tTest-logloss:0.166953\n",
      "[286]\tTest-logloss:0.166907\n",
      "[287]\tTest-logloss:0.166906\n",
      "[288]\tTest-logloss:0.166909\n",
      "[289]\tTest-logloss:0.166925\n",
      "[290]\tTest-logloss:0.166901\n",
      "[291]\tTest-logloss:0.166899\n",
      "[292]\tTest-logloss:0.166913\n",
      "[293]\tTest-logloss:0.16692\n",
      "[294]\tTest-logloss:0.16692\n",
      "[295]\tTest-logloss:0.166907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[296]\tTest-logloss:0.166909\n",
      "[297]\tTest-logloss:0.166893\n",
      "[298]\tTest-logloss:0.166921\n",
      "[299]\tTest-logloss:0.166848\n",
      "[300]\tTest-logloss:0.166843\n",
      "[301]\tTest-logloss:0.166804\n",
      "[302]\tTest-logloss:0.166812\n",
      "[303]\tTest-logloss:0.166815\n",
      "[304]\tTest-logloss:0.166825\n",
      "[305]\tTest-logloss:0.166823\n",
      "[306]\tTest-logloss:0.166816\n",
      "[307]\tTest-logloss:0.166839\n",
      "[308]\tTest-logloss:0.166858\n",
      "[309]\tTest-logloss:0.166833\n",
      "[310]\tTest-logloss:0.166831\n",
      "[311]\tTest-logloss:0.166842\n",
      "[312]\tTest-logloss:0.166843\n",
      "[313]\tTest-logloss:0.166777\n",
      "[314]\tTest-logloss:0.166765\n",
      "[315]\tTest-logloss:0.166783\n",
      "[316]\tTest-logloss:0.166796\n",
      "[317]\tTest-logloss:0.166782\n",
      "[318]\tTest-logloss:0.16679\n",
      "[319]\tTest-logloss:0.166812\n",
      "[320]\tTest-logloss:0.16681\n",
      "[321]\tTest-logloss:0.16682\n",
      "[322]\tTest-logloss:0.166871\n",
      "[323]\tTest-logloss:0.166883\n",
      "[324]\tTest-logloss:0.166904\n",
      "[325]\tTest-logloss:0.166934\n",
      "[326]\tTest-logloss:0.166952\n",
      "[327]\tTest-logloss:0.166953\n",
      "[328]\tTest-logloss:0.166964\n",
      "[329]\tTest-logloss:0.166961\n",
      "[330]\tTest-logloss:0.166971\n",
      "[331]\tTest-logloss:0.166984\n",
      "[332]\tTest-logloss:0.166945\n",
      "[333]\tTest-logloss:0.16695\n",
      "[334]\tTest-logloss:0.166947\n",
      "[335]\tTest-logloss:0.166967\n",
      "[336]\tTest-logloss:0.166959\n",
      "[337]\tTest-logloss:0.166948\n",
      "[338]\tTest-logloss:0.166954\n",
      "[339]\tTest-logloss:0.166875\n",
      "[340]\tTest-logloss:0.166885\n",
      "[341]\tTest-logloss:0.166906\n",
      "[342]\tTest-logloss:0.166929\n",
      "[343]\tTest-logloss:0.166892\n",
      "[344]\tTest-logloss:0.166905\n",
      "[345]\tTest-logloss:0.166927\n",
      "[346]\tTest-logloss:0.166925\n",
      "[347]\tTest-logloss:0.166929\n",
      "[348]\tTest-logloss:0.166956\n",
      "[349]\tTest-logloss:0.16694\n",
      "[350]\tTest-logloss:0.166967\n",
      "[351]\tTest-logloss:0.166967\n",
      "[352]\tTest-logloss:0.166958\n",
      "[353]\tTest-logloss:0.166956\n",
      "[354]\tTest-logloss:0.166957\n",
      "[355]\tTest-logloss:0.166968\n",
      "[356]\tTest-logloss:0.166874\n",
      "[357]\tTest-logloss:0.166882\n",
      "[358]\tTest-logloss:0.166877\n",
      "[359]\tTest-logloss:0.166842\n",
      "[360]\tTest-logloss:0.166857\n",
      "[361]\tTest-logloss:0.166891\n",
      "[362]\tTest-logloss:0.166923\n",
      "[363]\tTest-logloss:0.16691\n",
      "[364]\tTest-logloss:0.166911\n",
      "[365]\tTest-logloss:0.16691\n",
      "[366]\tTest-logloss:0.166918\n",
      "[367]\tTest-logloss:0.166922\n",
      "[368]\tTest-logloss:0.166922\n",
      "[369]\tTest-logloss:0.166929\n",
      "[370]\tTest-logloss:0.166951\n",
      "[371]\tTest-logloss:0.166969\n",
      "[372]\tTest-logloss:0.166984\n",
      "[373]\tTest-logloss:0.166986\n",
      "[374]\tTest-logloss:0.166994\n",
      "[375]\tTest-logloss:0.166985\n",
      "[376]\tTest-logloss:0.166995\n",
      "[377]\tTest-logloss:0.167004\n",
      "[378]\tTest-logloss:0.167027\n",
      "[379]\tTest-logloss:0.167023\n",
      "[380]\tTest-logloss:0.16703\n",
      "[381]\tTest-logloss:0.167036\n",
      "[382]\tTest-logloss:0.167075\n",
      "[383]\tTest-logloss:0.167095\n",
      "[384]\tTest-logloss:0.167115\n",
      "[385]\tTest-logloss:0.16711\n",
      "[386]\tTest-logloss:0.167115\n",
      "[387]\tTest-logloss:0.167085\n",
      "[388]\tTest-logloss:0.167105\n",
      "[389]\tTest-logloss:0.167116\n",
      "[390]\tTest-logloss:0.167137\n",
      "[391]\tTest-logloss:0.167106\n",
      "[392]\tTest-logloss:0.167133\n",
      "[393]\tTest-logloss:0.167133\n",
      "[394]\tTest-logloss:0.167112\n",
      "[395]\tTest-logloss:0.167104\n",
      "[396]\tTest-logloss:0.167101\n",
      "[397]\tTest-logloss:0.167104\n",
      "[398]\tTest-logloss:0.167118\n",
      "[399]\tTest-logloss:0.167112\n",
      "[400]\tTest-logloss:0.167133\n",
      "[401]\tTest-logloss:0.167132\n",
      "[402]\tTest-logloss:0.167169\n",
      "[403]\tTest-logloss:0.167135\n",
      "[404]\tTest-logloss:0.16716\n",
      "[405]\tTest-logloss:0.167137\n",
      "[406]\tTest-logloss:0.167139\n",
      "[407]\tTest-logloss:0.167148\n",
      "[408]\tTest-logloss:0.167155\n",
      "[409]\tTest-logloss:0.167181\n",
      "[410]\tTest-logloss:0.167179\n",
      "[411]\tTest-logloss:0.167156\n",
      "[412]\tTest-logloss:0.167113\n",
      "[413]\tTest-logloss:0.167126\n",
      "[414]\tTest-logloss:0.167145\n",
      "Stopping. Best iteration:\n",
      "[314]\tTest-logloss:0.166765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logloss: 0.17 with 315 rounds\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Logloss: {:.2f} with {} rounds\".format(\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_round = model.best_iteration+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round= boost_round\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
    " \n",
    "thresholds = np.append(thresholds, 1)\n",
    "f1_scores = 2*(precision*recall)/(precision+recall)\n",
    "plt.step(recall, precision, color='b', alpha=0.4, where='post')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold cutoff:  0.2831389009952545\n",
      "Max F1-score at cut-off :  0.5211754537597234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2bcc2ced390>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scrs = pd.DataFrame({'precision' : precision, 'recal' : recall, 'thresholds' : thresholds, 'f1_score':f1_scores})\n",
    "print(\"Threshold cutoff: \",scrs.loc[scrs['f1_score'] == scrs.f1_score.max(),'thresholds'].iloc[0])\n",
    "print(\"Max F1-score at cut-off : \",scrs.f1_score.max())\n",
    "scrs.plot(x='thresholds', y='f1_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_cutoff = scrs.loc[scrs['f1_score'] == scrs.f1_score.max(),'thresholds'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_data.drop(\"is_promoted\",axis=1), label=train_data['is_promoted'])\n",
    "dtest = xgb.DMatrix(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round= boost_round\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_pred(y, threshold= threshold_cutoff):\n",
    "    y_bin = [1 if y_cont > threshold else 0 for y_cont in y] # binarizing your output\n",
    "    return y_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(dtest)\n",
    "pred_new  = xgb_pred(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'employee_id': Emp_ID, 'is_promoted': pred_new}\n",
    "upload_XGB = pd.DataFrame(d)\n",
    "upload_XGB.to_csv(\"upload_XGB.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
