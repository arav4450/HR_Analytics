{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>department</th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>recruitment_channel</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>is_promoted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65438</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_7</td>\n",
       "      <td>Master's &amp; above</td>\n",
       "      <td>f</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65141</td>\n",
       "      <td>Operations</td>\n",
       "      <td>region_22</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7513</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_19</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2542</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_23</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48945</td>\n",
       "      <td>Technology</td>\n",
       "      <td>region_26</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id         department     region         education gender  \\\n",
       "0        65438  Sales & Marketing   region_7  Master's & above      f   \n",
       "1        65141         Operations  region_22        Bachelor's      m   \n",
       "2         7513  Sales & Marketing  region_19        Bachelor's      m   \n",
       "3         2542  Sales & Marketing  region_23        Bachelor's      m   \n",
       "4        48945         Technology  region_26        Bachelor's      m   \n",
       "\n",
       "  recruitment_channel  no_of_trainings  age  previous_year_rating  \\\n",
       "0            sourcing                1   35                   5.0   \n",
       "1               other                1   30                   5.0   \n",
       "2            sourcing                1   34                   3.0   \n",
       "3               other                2   39                   1.0   \n",
       "4               other                1   45                   3.0   \n",
       "\n",
       "   length_of_service  KPIs_met >80%  awards_won?  avg_training_score  \\\n",
       "0                  8              1            0                  49   \n",
       "1                  4              0            0                  60   \n",
       "2                  7              0            0                  50   \n",
       "3                 10              0            0                  50   \n",
       "4                  2              0            0                  73   \n",
       "\n",
       "   is_promoted  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_data, test_data]\n",
    "for df in data:\n",
    "    df.loc[df['avg_training_score'] > 73,'tr_score_cat'] = 'H'\n",
    "    df.loc[df['avg_training_score'] < 60,'tr_score_cat'] = 'L'\n",
    "    df.loc[(df['avg_training_score'] <= 73) & (df['avg_training_score'] >=\n",
    "                                               60),'tr_score_cat'] = 'M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = ['region_1','region_10','region_11','region_12','region_13','region_14','region_15','region_16','region_31','region_30','region_27','region_26','region_20','region_2','region_19','region_8']\n",
    "r2 = ['region_17','region_4','region_7','region_3','region_28','region_25','region_23','region_22']\n",
    "r3 = ['region_18','region_9','region_6','region_5','region_34','region_33','region_32','region_29','region_24','region_21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in data:\n",
    "    df.loc[df['region'].isin(r1) ,'region_gp'] = 1\n",
    "    df.loc[df['region'].isin(r2) ,'region_gp'] = 2\n",
    "    df.loc[df['region'].isin(r3) ,'region_gp'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in data:\n",
    "    df['KPI_AWard']  = df['KPIs_met >80%'] + df['awards_won?']\n",
    "    df['KPI_Rating']  = df['KPIs_met >80%'] + df['previous_year_rating']\n",
    "    df['AWard_Rating']  = df['awards_won?'] + df['previous_year_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numeric = ['avg_training_score', 'age', 'length_of_service', 'no_of_trainings']\n",
    "#category = ['KPIs_met >80%', 'awards_won?' ,'previous_year_rating', 'department', 'region', 'education', 'gender', 'recruitment_channel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in category:\n",
    "    #train_data[i] = train_data[i].astype('category')\n",
    "    #test_data[i] = test_data[i].astype('category')\n",
    "\n",
    "#train_data['is_promoted'] = train_data['is_promoted'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employee_id                0\n",
       "department                 0\n",
       "region                     0\n",
       "education               2409\n",
       "gender                     0\n",
       "recruitment_channel        0\n",
       "no_of_trainings            0\n",
       "age                        0\n",
       "previous_year_rating    4124\n",
       "length_of_service          0\n",
       "KPIs_met >80%              0\n",
       "awards_won?                0\n",
       "avg_training_score         0\n",
       "is_promoted                0\n",
       "tr_score_cat               0\n",
       "region_gp                  0\n",
       "KPI_AWard                  0\n",
       "KPI_Rating              4124\n",
       "AWard_Rating            4124\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employee_id                0\n",
       "department                 0\n",
       "region                     0\n",
       "education               1034\n",
       "gender                     0\n",
       "recruitment_channel        0\n",
       "no_of_trainings            0\n",
       "age                        0\n",
       "previous_year_rating    1812\n",
       "length_of_service          0\n",
       "KPIs_met >80%              0\n",
       "awards_won?                0\n",
       "avg_training_score         0\n",
       "tr_score_cat               0\n",
       "region_gp                  0\n",
       "KPI_AWard                  0\n",
       "KPI_Rating              1812\n",
       "AWard_Rating            1812\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Null values\n",
    "#train_data['education'] = train_data['education'].cat.add_categories('No Degree')\n",
    "train_data['education'].fillna('No Degree',inplace = True)\n",
    "#test_data['education'] = test_data['education'].cat.add_categories('No Degree')\n",
    "test_data['education'].fillna('No Degree',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Null values\n",
    "#train_data['previous_year_rating'] = train_data['previous_year_rating'].cat.add_categories('-999')\n",
    "train_data['previous_year_rating'].fillna(-999,inplace = True)\n",
    "#test_data['previous_year_rating'] = test_data['previous_year_rating'].cat.add_categories('-999')\n",
    "test_data['previous_year_rating'].fillna(-999,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Null values\n",
    "#train_data['previous_year_rating'] = train_data['previous_year_rating'].cat.add_categories('-999')\n",
    "train_data['KPI_Rating'].fillna(-999,inplace = True)\n",
    "#test_data['previous_year_rating'] = test_data['previous_year_rating'].cat.add_categories('-999')\n",
    "test_data['KPI_Rating'].fillna(-999,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Null values\n",
    "#train_data['previous_year_rating'] = train_data['previous_year_rating'].cat.add_categories('-999')\n",
    "train_data['AWard_Rating'].fillna(-999,inplace = True)\n",
    "#test_data['previous_year_rating'] = test_data['previous_year_rating'].cat.add_categories('-999')\n",
    "test_data['AWard_Rating'].fillna(-999,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employee_id             0\n",
       "department              0\n",
       "region                  0\n",
       "education               0\n",
       "gender                  0\n",
       "recruitment_channel     0\n",
       "no_of_trainings         0\n",
       "age                     0\n",
       "previous_year_rating    0\n",
       "length_of_service       0\n",
       "KPIs_met >80%           0\n",
       "awards_won?             0\n",
       "avg_training_score      0\n",
       "is_promoted             0\n",
       "tr_score_cat            0\n",
       "region_gp               0\n",
       "KPI_AWard               0\n",
       "KPI_Rating              0\n",
       "AWard_Rating            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "#scaler = StandardScaler()\n",
    "#for i in numeric:\n",
    "#   train_data[i] = scaler.fit_transform(train_data[i].values.reshape(-1,1))\n",
    "#   test_data[i] = scaler.fit_transform(test_data[i].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>department</th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>recruitment_channel</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>is_promoted</th>\n",
       "      <th>tr_score_cat</th>\n",
       "      <th>region_gp</th>\n",
       "      <th>KPI_AWard</th>\n",
       "      <th>KPI_Rating</th>\n",
       "      <th>AWard_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65438</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_7</td>\n",
       "      <td>Master's &amp; above</td>\n",
       "      <td>f</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65141</td>\n",
       "      <td>Operations</td>\n",
       "      <td>region_22</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7513</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_19</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2542</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_23</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48945</td>\n",
       "      <td>Technology</td>\n",
       "      <td>region_26</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id         department     region         education gender  \\\n",
       "0        65438  Sales & Marketing   region_7  Master's & above      f   \n",
       "1        65141         Operations  region_22        Bachelor's      m   \n",
       "2         7513  Sales & Marketing  region_19        Bachelor's      m   \n",
       "3         2542  Sales & Marketing  region_23        Bachelor's      m   \n",
       "4        48945         Technology  region_26        Bachelor's      m   \n",
       "\n",
       "  recruitment_channel  no_of_trainings  age  previous_year_rating  \\\n",
       "0            sourcing                1   35                   5.0   \n",
       "1               other                1   30                   5.0   \n",
       "2            sourcing                1   34                   3.0   \n",
       "3               other                2   39                   1.0   \n",
       "4               other                1   45                   3.0   \n",
       "\n",
       "   length_of_service  KPIs_met >80%  awards_won?  avg_training_score  \\\n",
       "0                  8              1            0                  49   \n",
       "1                  4              0            0                  60   \n",
       "2                  7              0            0                  50   \n",
       "3                 10              0            0                  50   \n",
       "4                  2              0            0                  73   \n",
       "\n",
       "   is_promoted tr_score_cat  region_gp  KPI_AWard  KPI_Rating  AWard_Rating  \n",
       "0            0            L        2.0          1         6.0           5.0  \n",
       "1            0            M        2.0          0         5.0           5.0  \n",
       "2            0            L        1.0          0         3.0           3.0  \n",
       "3            0            L        2.0          0         1.0           1.0  \n",
       "4            0            M        1.0          0         3.0           3.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LabelEncoding\n",
    "category_encode = ['previous_year_rating', 'department', 'region', 'education', 'gender', 'recruitment_channel','tr_score_cat','region_gp']\n",
    "le = LabelEncoder()\n",
    "for i in category_encode:\n",
    "    train_data[i] = le.fit_transform(train_data[i])\n",
    "    test_data[i] = le.transform(test_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping employee_id\n",
    "train_data.drop('employee_id', axis=1, inplace=True)\n",
    "Emp_ID = test_data['employee_id']\n",
    "test_data.drop('employee_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department</th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>recruitment_channel</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>is_promoted</th>\n",
       "      <th>tr_score_cat</th>\n",
       "      <th>region_gp</th>\n",
       "      <th>KPI_AWard</th>\n",
       "      <th>KPI_Rating</th>\n",
       "      <th>AWard_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   department  region  education  gender  recruitment_channel  \\\n",
       "0           7      31          2       0                    2   \n",
       "1           4      14          0       1                    0   \n",
       "2           7      10          0       1                    2   \n",
       "3           7      15          0       1                    0   \n",
       "4           8      18          0       1                    0   \n",
       "\n",
       "   no_of_trainings  age  previous_year_rating  length_of_service  \\\n",
       "0                1   35                     5                  8   \n",
       "1                1   30                     5                  4   \n",
       "2                1   34                     3                  7   \n",
       "3                2   39                     1                 10   \n",
       "4                1   45                     3                  2   \n",
       "\n",
       "   KPIs_met >80%  awards_won?  avg_training_score  is_promoted  tr_score_cat  \\\n",
       "0              1            0                  49            0             1   \n",
       "1              0            0                  60            0             2   \n",
       "2              0            0                  50            0             1   \n",
       "3              0            0                  50            0             1   \n",
       "4              0            0                  73            0             2   \n",
       "\n",
       "   region_gp  KPI_AWard  KPI_Rating  AWard_Rating  \n",
       "0          1          1         6.0           5.0  \n",
       "1          1          0         5.0           5.0  \n",
       "2          0          0         3.0           3.0  \n",
       "3          1          0         1.0           1.0  \n",
       "4          0          0         3.0           3.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department</th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>recruitment_channel</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>tr_score_cat</th>\n",
       "      <th>region_gp</th>\n",
       "      <th>KPI_AWard</th>\n",
       "      <th>KPI_Rating</th>\n",
       "      <th>AWard_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   department  region  education  gender  recruitment_channel  \\\n",
       "0           8      18          0       1                    2   \n",
       "1           2      28          0       0                    0   \n",
       "2           7       4          0       1                    0   \n",
       "3           5      11          0       0                    0   \n",
       "4           1      21          0       1                    2   \n",
       "\n",
       "   no_of_trainings  age  previous_year_rating  length_of_service  \\\n",
       "0                1   24                     0                  1   \n",
       "1                1   31                     3                  5   \n",
       "2                1   31                     1                  4   \n",
       "3                3   31                     2                  9   \n",
       "4                1   30                     4                  7   \n",
       "\n",
       "   KPIs_met >80%  awards_won?  avg_training_score  tr_score_cat  region_gp  \\\n",
       "0              1            0                  77             0          0   \n",
       "1              0            0                  51             1          1   \n",
       "2              0            0                  47             1          0   \n",
       "3              0            0                  65             2          0   \n",
       "4              0            0                  61             2          2   \n",
       "\n",
       "   KPI_AWard  KPI_Rating  AWard_Rating  \n",
       "0          1      -999.0        -999.0  \n",
       "1          0         3.0           3.0  \n",
       "2          0         1.0           1.0  \n",
       "3          0         2.0           2.0  \n",
       "4          0         4.0           4.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X = train_data.drop(\"is_promoted\",axis=1)\n",
    "Y = train_data[\"is_promoted\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.3, random_state=42, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'reg:logistic',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eval_metric'] = \"logloss\"\n",
    "num_boost_round = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-logloss:0.496994\n",
      "Will train until Test-logloss hasn't improved in 100 rounds.\n",
      "[1]\tTest-logloss:0.391314\n",
      "[2]\tTest-logloss:0.324795\n",
      "[3]\tTest-logloss:0.282938\n",
      "[4]\tTest-logloss:0.2492\n",
      "[5]\tTest-logloss:0.226897\n",
      "[6]\tTest-logloss:0.212656\n",
      "[7]\tTest-logloss:0.202516\n",
      "[8]\tTest-logloss:0.193865\n",
      "[9]\tTest-logloss:0.187322\n",
      "[10]\tTest-logloss:0.183556\n",
      "[11]\tTest-logloss:0.180516\n",
      "[12]\tTest-logloss:0.178308\n",
      "[13]\tTest-logloss:0.175218\n",
      "[14]\tTest-logloss:0.174017\n",
      "[15]\tTest-logloss:0.17273\n",
      "[16]\tTest-logloss:0.171304\n",
      "[17]\tTest-logloss:0.170958\n",
      "[18]\tTest-logloss:0.170772\n",
      "[19]\tTest-logloss:0.170657\n",
      "[20]\tTest-logloss:0.170356\n",
      "[21]\tTest-logloss:0.169902\n",
      "[22]\tTest-logloss:0.169372\n",
      "[23]\tTest-logloss:0.169382\n",
      "[24]\tTest-logloss:0.169343\n",
      "[25]\tTest-logloss:0.169107\n",
      "[26]\tTest-logloss:0.169184\n",
      "[27]\tTest-logloss:0.169232\n",
      "[28]\tTest-logloss:0.168274\n",
      "[29]\tTest-logloss:0.168367\n",
      "[30]\tTest-logloss:0.168305\n",
      "[31]\tTest-logloss:0.167653\n",
      "[32]\tTest-logloss:0.167975\n",
      "[33]\tTest-logloss:0.167942\n",
      "[34]\tTest-logloss:0.168142\n",
      "[35]\tTest-logloss:0.167806\n",
      "[36]\tTest-logloss:0.168123\n",
      "[37]\tTest-logloss:0.168137\n",
      "[38]\tTest-logloss:0.168021\n",
      "[39]\tTest-logloss:0.167734\n",
      "[40]\tTest-logloss:0.167738\n",
      "[41]\tTest-logloss:0.167529\n",
      "[42]\tTest-logloss:0.167804\n",
      "[43]\tTest-logloss:0.167826\n",
      "[44]\tTest-logloss:0.168058\n",
      "[45]\tTest-logloss:0.168046\n",
      "[46]\tTest-logloss:0.168215\n",
      "[47]\tTest-logloss:0.168106\n",
      "[48]\tTest-logloss:0.168096\n",
      "[49]\tTest-logloss:0.168206\n",
      "[50]\tTest-logloss:0.168242\n",
      "[51]\tTest-logloss:0.168316\n",
      "[52]\tTest-logloss:0.168373\n",
      "[53]\tTest-logloss:0.168444\n",
      "[54]\tTest-logloss:0.168747\n",
      "[55]\tTest-logloss:0.168227\n",
      "[56]\tTest-logloss:0.168332\n",
      "[57]\tTest-logloss:0.168416\n",
      "[58]\tTest-logloss:0.16845\n",
      "[59]\tTest-logloss:0.168583\n",
      "[60]\tTest-logloss:0.168715\n",
      "[61]\tTest-logloss:0.168771\n",
      "[62]\tTest-logloss:0.168688\n",
      "[63]\tTest-logloss:0.168749\n",
      "[64]\tTest-logloss:0.168846\n",
      "[65]\tTest-logloss:0.168944\n",
      "[66]\tTest-logloss:0.169188\n",
      "[67]\tTest-logloss:0.169122\n",
      "[68]\tTest-logloss:0.169121\n",
      "[69]\tTest-logloss:0.169156\n",
      "[70]\tTest-logloss:0.169226\n",
      "[71]\tTest-logloss:0.1693\n",
      "[72]\tTest-logloss:0.169606\n",
      "[73]\tTest-logloss:0.169656\n",
      "[74]\tTest-logloss:0.169881\n",
      "[75]\tTest-logloss:0.169797\n",
      "[76]\tTest-logloss:0.169927\n",
      "[77]\tTest-logloss:0.170041\n",
      "[78]\tTest-logloss:0.170154\n",
      "[79]\tTest-logloss:0.170103\n",
      "[80]\tTest-logloss:0.170148\n",
      "[81]\tTest-logloss:0.170299\n",
      "[82]\tTest-logloss:0.170213\n",
      "[83]\tTest-logloss:0.170182\n",
      "[84]\tTest-logloss:0.170328\n",
      "[85]\tTest-logloss:0.17024\n",
      "[86]\tTest-logloss:0.170502\n",
      "[87]\tTest-logloss:0.170451\n",
      "[88]\tTest-logloss:0.170666\n",
      "[89]\tTest-logloss:0.170984\n",
      "[90]\tTest-logloss:0.171113\n",
      "[91]\tTest-logloss:0.17121\n",
      "[92]\tTest-logloss:0.171531\n",
      "[93]\tTest-logloss:0.171736\n",
      "[94]\tTest-logloss:0.171736\n",
      "[95]\tTest-logloss:0.172043\n",
      "[96]\tTest-logloss:0.172313\n",
      "[97]\tTest-logloss:0.172381\n",
      "[98]\tTest-logloss:0.172306\n",
      "[99]\tTest-logloss:0.172483\n",
      "[100]\tTest-logloss:0.17255\n",
      "[101]\tTest-logloss:0.172704\n",
      "[102]\tTest-logloss:0.172646\n",
      "[103]\tTest-logloss:0.172765\n",
      "[104]\tTest-logloss:0.172829\n",
      "[105]\tTest-logloss:0.172946\n",
      "[106]\tTest-logloss:0.173071\n",
      "[107]\tTest-logloss:0.172967\n",
      "[108]\tTest-logloss:0.172981\n",
      "[109]\tTest-logloss:0.173094\n",
      "[110]\tTest-logloss:0.173343\n",
      "[111]\tTest-logloss:0.173518\n",
      "[112]\tTest-logloss:0.173572\n",
      "[113]\tTest-logloss:0.173827\n",
      "[114]\tTest-logloss:0.174037\n",
      "[115]\tTest-logloss:0.174186\n",
      "[116]\tTest-logloss:0.174432\n",
      "[117]\tTest-logloss:0.174527\n",
      "[118]\tTest-logloss:0.17475\n",
      "[119]\tTest-logloss:0.175004\n",
      "[120]\tTest-logloss:0.175256\n",
      "[121]\tTest-logloss:0.175451\n",
      "[122]\tTest-logloss:0.175601\n",
      "[123]\tTest-logloss:0.175706\n",
      "[124]\tTest-logloss:0.175685\n",
      "[125]\tTest-logloss:0.175801\n",
      "[126]\tTest-logloss:0.175826\n",
      "[127]\tTest-logloss:0.175977\n",
      "[128]\tTest-logloss:0.175953\n",
      "[129]\tTest-logloss:0.176189\n",
      "[130]\tTest-logloss:0.176347\n",
      "[131]\tTest-logloss:0.176421\n",
      "[132]\tTest-logloss:0.176449\n",
      "[133]\tTest-logloss:0.176459\n",
      "[134]\tTest-logloss:0.176484\n",
      "[135]\tTest-logloss:0.176584\n",
      "[136]\tTest-logloss:0.176622\n",
      "[137]\tTest-logloss:0.176792\n",
      "[138]\tTest-logloss:0.176833\n",
      "[139]\tTest-logloss:0.17683\n",
      "[140]\tTest-logloss:0.176823\n",
      "[141]\tTest-logloss:0.176911\n",
      "Stopping. Best iteration:\n",
      "[41]\tTest-logloss:0.167529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logloss: 0.17 with 42 rounds\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Logloss: {:.2f} with {} rounds\".format(\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_data.drop(\"is_promoted\",axis=1), label=train_data['is_promoted'])\n",
    "dtest = xgb.DMatrix(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-logloss-mean</th>\n",
       "      <th>train-logloss-std</th>\n",
       "      <th>test-logloss-mean</th>\n",
       "      <th>test-logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.498719</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.499242</td>\n",
       "      <td>0.001890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.389428</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.390560</td>\n",
       "      <td>0.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.323225</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.324869</td>\n",
       "      <td>0.003768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279149</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.281353</td>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.247114</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.249678</td>\n",
       "      <td>0.005336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.224939</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.227880</td>\n",
       "      <td>0.006758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.209475</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.212645</td>\n",
       "      <td>0.006839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.197980</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>0.201668</td>\n",
       "      <td>0.006596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.189123</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>0.193151</td>\n",
       "      <td>0.006488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.182350</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.186676</td>\n",
       "      <td>0.006405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.177110</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>0.181901</td>\n",
       "      <td>0.006063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.173092</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.178428</td>\n",
       "      <td>0.005910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.169972</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.175786</td>\n",
       "      <td>0.005674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.167243</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>0.173645</td>\n",
       "      <td>0.005688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.164794</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.171758</td>\n",
       "      <td>0.005501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.162861</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>0.170431</td>\n",
       "      <td>0.005649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.161819</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.169783</td>\n",
       "      <td>0.005561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.160872</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.169267</td>\n",
       "      <td>0.005482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.159801</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.168791</td>\n",
       "      <td>0.005582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.158656</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.168294</td>\n",
       "      <td>0.005760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.157796</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.167954</td>\n",
       "      <td>0.005828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.156841</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>0.167609</td>\n",
       "      <td>0.005942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.156218</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.167358</td>\n",
       "      <td>0.005865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.155262</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.167030</td>\n",
       "      <td>0.006084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.154408</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.166843</td>\n",
       "      <td>0.005882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.153684</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>0.166717</td>\n",
       "      <td>0.005742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.152808</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.166415</td>\n",
       "      <td>0.006010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.152045</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.166404</td>\n",
       "      <td>0.006006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.151507</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.166331</td>\n",
       "      <td>0.005932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.150884</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.166255</td>\n",
       "      <td>0.006016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.150231</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.166250</td>\n",
       "      <td>0.005942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.149582</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.166258</td>\n",
       "      <td>0.005882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.148807</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.165893</td>\n",
       "      <td>0.006173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.148048</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.165770</td>\n",
       "      <td>0.006204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.147566</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.165828</td>\n",
       "      <td>0.006137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.147054</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>0.165770</td>\n",
       "      <td>0.006020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.146301</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.165754</td>\n",
       "      <td>0.006108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.145779</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.165833</td>\n",
       "      <td>0.006074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.145354</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.165818</td>\n",
       "      <td>0.006146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.144628</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>0.165835</td>\n",
       "      <td>0.006138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.143910</td>\n",
       "      <td>0.002180</td>\n",
       "      <td>0.165923</td>\n",
       "      <td>0.006182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.143423</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>0.165793</td>\n",
       "      <td>0.006200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.142893</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.165733</td>\n",
       "      <td>0.006180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.142359</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>0.165703</td>\n",
       "      <td>0.006186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.141688</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.165669</td>\n",
       "      <td>0.006544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.141266</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>0.165804</td>\n",
       "      <td>0.006621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.140935</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.165811</td>\n",
       "      <td>0.006648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.140450</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>0.165867</td>\n",
       "      <td>0.006540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.139992</td>\n",
       "      <td>0.001547</td>\n",
       "      <td>0.165878</td>\n",
       "      <td>0.006471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.139402</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.165912</td>\n",
       "      <td>0.006414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.139045</td>\n",
       "      <td>0.001725</td>\n",
       "      <td>0.165894</td>\n",
       "      <td>0.006466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.138677</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.165843</td>\n",
       "      <td>0.006375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.138065</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.165575</td>\n",
       "      <td>0.006385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-logloss-mean  train-logloss-std  test-logloss-mean  test-logloss-std\n",
       "0             0.498719           0.000329           0.499242          0.001890\n",
       "1             0.389428           0.000778           0.390560          0.003128\n",
       "2             0.323225           0.000837           0.324869          0.003768\n",
       "3             0.279149           0.001909           0.281353          0.004700\n",
       "4             0.247114           0.002092           0.249678          0.005336\n",
       "5             0.224939           0.001745           0.227880          0.006758\n",
       "6             0.209475           0.002026           0.212645          0.006839\n",
       "7             0.197980           0.001544           0.201668          0.006596\n",
       "8             0.189123           0.001694           0.193151          0.006488\n",
       "9             0.182350           0.001249           0.186676          0.006405\n",
       "10            0.177110           0.001363           0.181901          0.006063\n",
       "11            0.173092           0.001631           0.178428          0.005910\n",
       "12            0.169972           0.001623           0.175786          0.005674\n",
       "13            0.167243           0.001732           0.173645          0.005688\n",
       "14            0.164794           0.001914           0.171758          0.005501\n",
       "15            0.162861           0.001819           0.170431          0.005649\n",
       "16            0.161819           0.001790           0.169783          0.005561\n",
       "17            0.160872           0.001888           0.169267          0.005482\n",
       "18            0.159801           0.001918           0.168791          0.005582\n",
       "19            0.158656           0.001780           0.168294          0.005760\n",
       "20            0.157796           0.001764           0.167954          0.005828\n",
       "21            0.156841           0.001820           0.167609          0.005942\n",
       "22            0.156218           0.001856           0.167358          0.005865\n",
       "23            0.155262           0.001640           0.167030          0.006084\n",
       "24            0.154408           0.001858           0.166843          0.005882\n",
       "25            0.153684           0.001812           0.166717          0.005742\n",
       "26            0.152808           0.001683           0.166415          0.006010\n",
       "27            0.152045           0.001585           0.166404          0.006006\n",
       "28            0.151507           0.001855           0.166331          0.005932\n",
       "29            0.150884           0.001824           0.166255          0.006016\n",
       "30            0.150231           0.002016           0.166250          0.005942\n",
       "31            0.149582           0.002222           0.166258          0.005882\n",
       "32            0.148807           0.002056           0.165893          0.006173\n",
       "33            0.148048           0.001930           0.165770          0.006204\n",
       "34            0.147566           0.002040           0.165828          0.006137\n",
       "35            0.147054           0.002067           0.165770          0.006020\n",
       "36            0.146301           0.001914           0.165754          0.006108\n",
       "37            0.145779           0.001928           0.165833          0.006074\n",
       "38            0.145354           0.001963           0.165818          0.006146\n",
       "39            0.144628           0.002098           0.165835          0.006138\n",
       "40            0.143910           0.002180           0.165923          0.006182\n",
       "41            0.143423           0.002182           0.165793          0.006200\n",
       "42            0.142893           0.002045           0.165733          0.006180\n",
       "43            0.142359           0.002132           0.165703          0.006186\n",
       "44            0.141688           0.001952           0.165669          0.006544\n",
       "45            0.141266           0.001817           0.165804          0.006621\n",
       "46            0.140935           0.001739           0.165811          0.006648\n",
       "47            0.140450           0.001584           0.165867          0.006540\n",
       "48            0.139992           0.001547           0.165878          0.006471\n",
       "49            0.139402           0.001703           0.165912          0.006414\n",
       "50            0.139045           0.001725           0.165894          0.006466\n",
       "51            0.138677           0.001633           0.165843          0.006375\n",
       "52            0.138065           0.001714           0.165575          0.006385"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'logloss'},\n",
    "    early_stopping_rounds=100\n",
    ")\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16557539999999998"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test-logloss-mean'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can try wider intervals with a larger step between\n",
    "# each value and then narrow it down. Here after several\n",
    "# iteration I found that the optimal value was in the\n",
    "# following ranges.\n",
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(7,10)\n",
    "    for min_child_weight in range(5,8)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=7, min_child_weight=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: \n",
      "The current behaviour of 'Series.argmin' is deprecated, use 'idxmin'\n",
      "instead.\n",
      "The behavior of 'argmin' will be corrected to return the positional\n",
      "minimum in the future. For now, use 'series.values.argmin' or\n",
      "'np.argmin(np.array(values))' to get the position of the minimum\n",
      "row.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLogLoss 0.165912 for 36 rounds\n",
      "CV with max_depth=7, min_child_weight=6\n",
      "\tLogLoss 0.165544 for 40 rounds\n",
      "CV with max_depth=7, min_child_weight=7\n",
      "\tLogLoss 0.1659192 for 33 rounds\n",
      "CV with max_depth=8, min_child_weight=5\n",
      "\tLogLoss 0.1662502 for 33 rounds\n",
      "CV with max_depth=8, min_child_weight=6\n",
      "\tLogLoss 0.1668366 for 30 rounds\n",
      "CV with max_depth=8, min_child_weight=7\n",
      "\tLogLoss 0.166424 for 36 rounds\n",
      "CV with max_depth=9, min_child_weight=5\n",
      "\tLogLoss 0.1672172 for 26 rounds\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "\tLogLoss 0.1668898 for 28 rounds\n",
      "CV with max_depth=9, min_child_weight=7\n",
      "\tLogLoss 0.166949 for 30 rounds\n",
      "Best params: 7, 6, logloss: 0.165544\n"
     ]
    }
   ],
   "source": [
    "# Define initial best params and Logloss\n",
    "min_logloss = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'logloss'},\n",
    "        early_stopping_rounds=100\n",
    "    )\n",
    "    # Update best MAE\n",
    "    mean_logloss = cv_results['test-logloss-mean'].min()\n",
    "    boost_rounds = cv_results['test-logloss-mean'].argmin()\n",
    "    print(\"\\tLogLoss {} for {} rounds\".format(mean_logloss, boost_rounds))\n",
    "    if mean_logloss < min_logloss:\n",
    "        min_logloss = mean_logloss\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, logloss: {}\".format(best_params[0], best_params[1], min_logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = best_params[0]\n",
    "params['min_child_weight'] = best_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: \n",
      "The current behaviour of 'Series.argmin' is deprecated, use 'idxmin'\n",
      "instead.\n",
      "The behavior of 'argmin' will be corrected to return the positional\n",
      "minimum in the future. For now, use 'series.values.argmin' or\n",
      "'np.argmin(np.array(values))' to get the position of the minimum\n",
      "row.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMAE 0.165544 for 40 rounds\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "\tMAE 0.16554059999999998 for 36 rounds\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "\tMAE 0.1651968 for 38 rounds\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "\tMAE 0.1657892 for 36 rounds\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "\tMAE 0.1669066 for 37 rounds\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "\tMAE 0.16651339999999998 for 37 rounds\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "\tMAE 0.166336 for 33 rounds\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "\tMAE 0.16627240000000001 for 38 rounds\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "\tMAE 0.16780299999999998 for 42 rounds\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "\tMAE 0.1669862 for 30 rounds\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "\tMAE 0.16731659999999998 for 43 rounds\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "\tMAE 0.167471 for 42 rounds\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "\tMAE 0.1681516 for 30 rounds\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "\tMAE 0.16790000000000002 for 24 rounds\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "\tMAE 0.1681536 for 29 rounds\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "\tMAE 0.16830099999999998 for 37 rounds\n",
      "Best params: 1.0, 0.8, Logloss: 0.1651968\n"
     ]
    }
   ],
   "source": [
    "min_logloss = float(\"Inf\")\n",
    "best_params = None\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'logloss'},\n",
    "        early_stopping_rounds=100\n",
    "    )\n",
    "    # Update best score\n",
    "    mean_logloss = cv_results['test-logloss-mean'].min()\n",
    "    boost_rounds = cv_results['test-logloss-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_logloss, boost_rounds))\n",
    "    if mean_logloss < min_logloss:\n",
    "        min_logloss = mean_logloss\n",
    "        best_params = (subsample,colsample)\n",
    "print(\"Best params: {}, {}, Logloss: {}\".format(best_params[0], best_params[1], min_logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['subsample'] = best_params[0]\n",
    "params['colsample_bytree'] = best_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "CV with eta=0.3\n",
      "Wall time: 7.53 s\n",
      "\tLogloss 0.1651968 for 38 rounds\n",
      "\n",
      "CV with eta=0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: \n",
      "The current behaviour of 'Series.argmin' is deprecated, use 'idxmin'\n",
      "instead.\n",
      "The behavior of 'argmin' will be corrected to return the positional\n",
      "minimum in the future. For now, use 'series.values.argmin' or\n",
      "'np.argmin(np.array(values))' to get the position of the minimum\n",
      "row.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.91 s\n",
      "\tLogloss 0.16437820000000003 for 60 rounds\n",
      "\n",
      "CV with eta=0.1\n",
      "Wall time: 13.5 s\n",
      "\tLogloss 0.16436420000000002 for 148 rounds\n",
      "\n",
      "CV with eta=0.05\n",
      "Wall time: 21 s\n",
      "\tLogloss 0.16394219999999998 for 284 rounds\n",
      "\n",
      "CV with eta=0.01\n",
      "Wall time: 55.6 s\n",
      "\tLogloss 0.16458679999999998 for 998 rounds\n",
      "\n",
      "CV with eta=0.005\n",
      "Wall time: 56.5 s\n",
      "\tLogloss 0.17045400000000002 for 998 rounds\n",
      "\n",
      "Best params: 0.05, Logloss: 0.16394219999999998\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# This can take some time\n",
    "min_logloss = float(\"Inf\")\n",
    "best_params = None\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "    # Run and time CV\n",
    "    %time cv_results = xgb.cv(params,dtrain,num_boost_round=num_boost_round,seed=42,nfold=5,metrics=['logloss'],early_stopping_rounds=100)\n",
    "    # Update best score\n",
    "    mean_logloss = cv_results['test-logloss-mean'].min()\n",
    "    boost_rounds = cv_results['test-logloss-mean'].argmin()\n",
    "    print(\"\\tLogloss {} for {} rounds\\n\".format(mean_logloss, boost_rounds))\n",
    "    if mean_logloss < min_logloss:\n",
    "        min_logloss = mean_logloss\n",
    "        best_params = eta\n",
    "        \n",
    "print(\"Best params: {}, Logloss: {}\".format(best_params, min_logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eta'] = best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7,\n",
       " 'min_child_weight': 6,\n",
       " 'eta': 0.05,\n",
       " 'subsample': 1.0,\n",
       " 'colsample_bytree': 0.8,\n",
       " 'objective': 'reg:logistic',\n",
       " 'eval_metric': 'logloss'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-logloss:0.655686\n",
      "Will train until Test-logloss hasn't improved in 100 rounds.\n",
      "[1]\tTest-logloss:0.621821\n",
      "[2]\tTest-logloss:0.59086\n",
      "[3]\tTest-logloss:0.562654\n",
      "[4]\tTest-logloss:0.537599\n",
      "[5]\tTest-logloss:0.513918\n",
      "[6]\tTest-logloss:0.491987\n",
      "[7]\tTest-logloss:0.472084\n",
      "[8]\tTest-logloss:0.453595\n",
      "[9]\tTest-logloss:0.437409\n",
      "[10]\tTest-logloss:0.421628\n",
      "[11]\tTest-logloss:0.406925\n",
      "[12]\tTest-logloss:0.393134\n",
      "[13]\tTest-logloss:0.38003\n",
      "[14]\tTest-logloss:0.368547\n",
      "[15]\tTest-logloss:0.357832\n",
      "[16]\tTest-logloss:0.347526\n",
      "[17]\tTest-logloss:0.338241\n",
      "[18]\tTest-logloss:0.328954\n",
      "[19]\tTest-logloss:0.320829\n",
      "[20]\tTest-logloss:0.312936\n",
      "[21]\tTest-logloss:0.305701\n",
      "[22]\tTest-logloss:0.298561\n",
      "[23]\tTest-logloss:0.29261\n",
      "[24]\tTest-logloss:0.286817\n",
      "[25]\tTest-logloss:0.281536\n",
      "[26]\tTest-logloss:0.276644\n",
      "[27]\tTest-logloss:0.270615\n",
      "[28]\tTest-logloss:0.266147\n",
      "[29]\tTest-logloss:0.261491\n",
      "[30]\tTest-logloss:0.257247\n",
      "[31]\tTest-logloss:0.252525\n",
      "[32]\tTest-logloss:0.248794\n",
      "[33]\tTest-logloss:0.245032\n",
      "[34]\tTest-logloss:0.241562\n",
      "[35]\tTest-logloss:0.238916\n",
      "[36]\tTest-logloss:0.235951\n",
      "[37]\tTest-logloss:0.233\n",
      "[38]\tTest-logloss:0.230595\n",
      "[39]\tTest-logloss:0.228366\n",
      "[40]\tTest-logloss:0.225316\n",
      "[41]\tTest-logloss:0.223521\n",
      "[42]\tTest-logloss:0.221082\n",
      "[43]\tTest-logloss:0.219523\n",
      "[44]\tTest-logloss:0.217413\n",
      "[45]\tTest-logloss:0.214877\n",
      "[46]\tTest-logloss:0.213396\n",
      "[47]\tTest-logloss:0.21172\n",
      "[48]\tTest-logloss:0.209579\n",
      "[49]\tTest-logloss:0.207592\n",
      "[50]\tTest-logloss:0.206211\n",
      "[51]\tTest-logloss:0.20404\n",
      "[52]\tTest-logloss:0.202636\n",
      "[53]\tTest-logloss:0.200719\n",
      "[54]\tTest-logloss:0.198945\n",
      "[55]\tTest-logloss:0.197788\n",
      "[56]\tTest-logloss:0.196214\n",
      "[57]\tTest-logloss:0.195494\n",
      "[58]\tTest-logloss:0.194062\n",
      "[59]\tTest-logloss:0.193399\n",
      "[60]\tTest-logloss:0.192776\n",
      "[61]\tTest-logloss:0.191487\n",
      "[62]\tTest-logloss:0.190374\n",
      "[63]\tTest-logloss:0.189203\n",
      "[64]\tTest-logloss:0.188046\n",
      "[65]\tTest-logloss:0.187438\n",
      "[66]\tTest-logloss:0.186441\n",
      "[67]\tTest-logloss:0.185559\n",
      "[68]\tTest-logloss:0.184655\n",
      "[69]\tTest-logloss:0.184372\n",
      "[70]\tTest-logloss:0.184009\n",
      "[71]\tTest-logloss:0.183108\n",
      "[72]\tTest-logloss:0.182642\n",
      "[73]\tTest-logloss:0.181829\n",
      "[74]\tTest-logloss:0.181436\n",
      "[75]\tTest-logloss:0.18095\n",
      "[76]\tTest-logloss:0.180711\n",
      "[77]\tTest-logloss:0.180045\n",
      "[78]\tTest-logloss:0.179404\n",
      "[79]\tTest-logloss:0.178832\n",
      "[80]\tTest-logloss:0.178538\n",
      "[81]\tTest-logloss:0.178303\n",
      "[82]\tTest-logloss:0.177826\n",
      "[83]\tTest-logloss:0.1773\n",
      "[84]\tTest-logloss:0.176836\n",
      "[85]\tTest-logloss:0.176239\n",
      "[86]\tTest-logloss:0.176093\n",
      "[87]\tTest-logloss:0.175889\n",
      "[88]\tTest-logloss:0.175696\n",
      "[89]\tTest-logloss:0.175175\n",
      "[90]\tTest-logloss:0.17484\n",
      "[91]\tTest-logloss:0.174374\n",
      "[92]\tTest-logloss:0.174095\n",
      "[93]\tTest-logloss:0.173653\n",
      "[94]\tTest-logloss:0.173387\n",
      "[95]\tTest-logloss:0.173296\n",
      "[96]\tTest-logloss:0.172973\n",
      "[97]\tTest-logloss:0.172693\n",
      "[98]\tTest-logloss:0.172618\n",
      "[99]\tTest-logloss:0.172255\n",
      "[100]\tTest-logloss:0.172018\n",
      "[101]\tTest-logloss:0.171947\n",
      "[102]\tTest-logloss:0.171906\n",
      "[103]\tTest-logloss:0.171829\n",
      "[104]\tTest-logloss:0.171777\n",
      "[105]\tTest-logloss:0.171439\n",
      "[106]\tTest-logloss:0.171236\n",
      "[107]\tTest-logloss:0.171187\n",
      "[108]\tTest-logloss:0.171102\n",
      "[109]\tTest-logloss:0.171028\n",
      "[110]\tTest-logloss:0.170791\n",
      "[111]\tTest-logloss:0.170577\n",
      "[112]\tTest-logloss:0.170524\n",
      "[113]\tTest-logloss:0.170509\n",
      "[114]\tTest-logloss:0.170261\n",
      "[115]\tTest-logloss:0.170244\n",
      "[116]\tTest-logloss:0.170206\n",
      "[117]\tTest-logloss:0.170169\n",
      "[118]\tTest-logloss:0.17013\n",
      "[119]\tTest-logloss:0.16999\n",
      "[120]\tTest-logloss:0.169951\n",
      "[121]\tTest-logloss:0.169838\n",
      "[122]\tTest-logloss:0.169832\n",
      "[123]\tTest-logloss:0.169779\n",
      "[124]\tTest-logloss:0.169719\n",
      "[125]\tTest-logloss:0.169647\n",
      "[126]\tTest-logloss:0.169639\n",
      "[127]\tTest-logloss:0.169545\n",
      "[128]\tTest-logloss:0.16951\n",
      "[129]\tTest-logloss:0.169524\n",
      "[130]\tTest-logloss:0.16947\n",
      "[131]\tTest-logloss:0.16946\n",
      "[132]\tTest-logloss:0.16943\n",
      "[133]\tTest-logloss:0.169331\n",
      "[134]\tTest-logloss:0.169145\n",
      "[135]\tTest-logloss:0.169121\n",
      "[136]\tTest-logloss:0.168921\n",
      "[137]\tTest-logloss:0.168864\n",
      "[138]\tTest-logloss:0.168814\n",
      "[139]\tTest-logloss:0.168781\n",
      "[140]\tTest-logloss:0.16881\n",
      "[141]\tTest-logloss:0.168555\n",
      "[142]\tTest-logloss:0.168486\n",
      "[143]\tTest-logloss:0.168481\n",
      "[144]\tTest-logloss:0.168496\n",
      "[145]\tTest-logloss:0.168415\n",
      "[146]\tTest-logloss:0.168339\n",
      "[147]\tTest-logloss:0.168366\n",
      "[148]\tTest-logloss:0.168345\n",
      "[149]\tTest-logloss:0.168341\n",
      "[150]\tTest-logloss:0.168332\n",
      "[151]\tTest-logloss:0.168323\n",
      "[152]\tTest-logloss:0.168277\n",
      "[153]\tTest-logloss:0.168244\n",
      "[154]\tTest-logloss:0.168245\n",
      "[155]\tTest-logloss:0.168185\n",
      "[156]\tTest-logloss:0.16816\n",
      "[157]\tTest-logloss:0.168173\n",
      "[158]\tTest-logloss:0.168134\n",
      "[159]\tTest-logloss:0.168077\n",
      "[160]\tTest-logloss:0.168117\n",
      "[161]\tTest-logloss:0.168059\n",
      "[162]\tTest-logloss:0.168066\n",
      "[163]\tTest-logloss:0.168065\n",
      "[164]\tTest-logloss:0.168032\n",
      "[165]\tTest-logloss:0.167813\n",
      "[166]\tTest-logloss:0.167835\n",
      "[167]\tTest-logloss:0.167627\n",
      "[168]\tTest-logloss:0.167596\n",
      "[169]\tTest-logloss:0.167588\n",
      "[170]\tTest-logloss:0.167568\n",
      "[171]\tTest-logloss:0.167368\n",
      "[172]\tTest-logloss:0.167349\n",
      "[173]\tTest-logloss:0.167346\n",
      "[174]\tTest-logloss:0.167348\n",
      "[175]\tTest-logloss:0.167336\n",
      "[176]\tTest-logloss:0.167339\n",
      "[177]\tTest-logloss:0.167353\n",
      "[178]\tTest-logloss:0.167306\n",
      "[179]\tTest-logloss:0.167214\n",
      "[180]\tTest-logloss:0.1672\n",
      "[181]\tTest-logloss:0.167204\n",
      "[182]\tTest-logloss:0.167208\n",
      "[183]\tTest-logloss:0.167206\n",
      "[184]\tTest-logloss:0.167205\n",
      "[185]\tTest-logloss:0.167222\n",
      "[186]\tTest-logloss:0.167276\n",
      "[187]\tTest-logloss:0.167293\n",
      "[188]\tTest-logloss:0.167328\n",
      "[189]\tTest-logloss:0.167345\n",
      "[190]\tTest-logloss:0.167355\n",
      "[191]\tTest-logloss:0.167351\n",
      "[192]\tTest-logloss:0.167385\n",
      "[193]\tTest-logloss:0.167297\n",
      "[194]\tTest-logloss:0.167313\n",
      "[195]\tTest-logloss:0.167337\n",
      "[196]\tTest-logloss:0.167308\n",
      "[197]\tTest-logloss:0.167306\n",
      "[198]\tTest-logloss:0.167321\n",
      "[199]\tTest-logloss:0.167281\n",
      "[200]\tTest-logloss:0.167292\n",
      "[201]\tTest-logloss:0.167319\n",
      "[202]\tTest-logloss:0.167298\n",
      "[203]\tTest-logloss:0.167298\n",
      "[204]\tTest-logloss:0.16733\n",
      "[205]\tTest-logloss:0.167345\n",
      "[206]\tTest-logloss:0.167347\n",
      "[207]\tTest-logloss:0.167367\n",
      "[208]\tTest-logloss:0.167371\n",
      "[209]\tTest-logloss:0.167267\n",
      "[210]\tTest-logloss:0.167259\n",
      "[211]\tTest-logloss:0.16726\n",
      "[212]\tTest-logloss:0.167261\n",
      "[213]\tTest-logloss:0.167255\n",
      "[214]\tTest-logloss:0.167285\n",
      "[215]\tTest-logloss:0.167305\n",
      "[216]\tTest-logloss:0.167308\n",
      "[217]\tTest-logloss:0.167304\n",
      "[218]\tTest-logloss:0.167298\n",
      "[219]\tTest-logloss:0.167183\n",
      "[220]\tTest-logloss:0.167169\n",
      "[221]\tTest-logloss:0.167165\n",
      "[222]\tTest-logloss:0.167087\n",
      "[223]\tTest-logloss:0.167093\n",
      "[224]\tTest-logloss:0.167087\n",
      "[225]\tTest-logloss:0.167104\n",
      "[226]\tTest-logloss:0.167095\n",
      "[227]\tTest-logloss:0.16701\n",
      "[228]\tTest-logloss:0.167029\n",
      "[229]\tTest-logloss:0.167036\n",
      "[230]\tTest-logloss:0.167055\n",
      "[231]\tTest-logloss:0.167054\n",
      "[232]\tTest-logloss:0.167047\n",
      "[233]\tTest-logloss:0.167034\n",
      "[234]\tTest-logloss:0.167067\n",
      "[235]\tTest-logloss:0.167049\n",
      "[236]\tTest-logloss:0.167083\n",
      "[237]\tTest-logloss:0.167106\n",
      "[238]\tTest-logloss:0.167108\n",
      "[239]\tTest-logloss:0.167054\n",
      "[240]\tTest-logloss:0.167052\n",
      "[241]\tTest-logloss:0.167024\n",
      "[242]\tTest-logloss:0.167016\n",
      "[243]\tTest-logloss:0.167064\n",
      "[244]\tTest-logloss:0.167069\n",
      "[245]\tTest-logloss:0.167078\n",
      "[246]\tTest-logloss:0.16706\n",
      "[247]\tTest-logloss:0.167088\n",
      "[248]\tTest-logloss:0.167084\n",
      "[249]\tTest-logloss:0.167064\n",
      "[250]\tTest-logloss:0.167072\n",
      "[251]\tTest-logloss:0.167004\n",
      "[252]\tTest-logloss:0.167014\n",
      "[253]\tTest-logloss:0.167016\n",
      "[254]\tTest-logloss:0.167023\n",
      "[255]\tTest-logloss:0.166965\n",
      "[256]\tTest-logloss:0.167001\n",
      "[257]\tTest-logloss:0.166989\n",
      "[258]\tTest-logloss:0.166982\n",
      "[259]\tTest-logloss:0.166943\n",
      "[260]\tTest-logloss:0.166963\n",
      "[261]\tTest-logloss:0.166968\n",
      "[262]\tTest-logloss:0.166984\n",
      "[263]\tTest-logloss:0.167001\n",
      "[264]\tTest-logloss:0.166983\n",
      "[265]\tTest-logloss:0.167005\n",
      "[266]\tTest-logloss:0.16703\n",
      "[267]\tTest-logloss:0.167024\n",
      "[268]\tTest-logloss:0.16703\n",
      "[269]\tTest-logloss:0.167056\n",
      "[270]\tTest-logloss:0.167078\n",
      "[271]\tTest-logloss:0.167089\n",
      "[272]\tTest-logloss:0.167105\n",
      "[273]\tTest-logloss:0.167114\n",
      "[274]\tTest-logloss:0.167059\n",
      "[275]\tTest-logloss:0.166992\n",
      "[276]\tTest-logloss:0.16698\n",
      "[277]\tTest-logloss:0.167018\n",
      "[278]\tTest-logloss:0.167042\n",
      "[279]\tTest-logloss:0.167039\n",
      "[280]\tTest-logloss:0.167009\n",
      "[281]\tTest-logloss:0.167007\n",
      "[282]\tTest-logloss:0.167006\n",
      "[283]\tTest-logloss:0.166916\n",
      "[284]\tTest-logloss:0.166949\n",
      "[285]\tTest-logloss:0.166908\n",
      "[286]\tTest-logloss:0.166932\n",
      "[287]\tTest-logloss:0.166915\n",
      "[288]\tTest-logloss:0.166917\n",
      "[289]\tTest-logloss:0.166945\n",
      "[290]\tTest-logloss:0.166923\n",
      "[291]\tTest-logloss:0.166879\n",
      "[292]\tTest-logloss:0.166883\n",
      "[293]\tTest-logloss:0.166882\n",
      "[294]\tTest-logloss:0.166871\n",
      "[295]\tTest-logloss:0.166865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[296]\tTest-logloss:0.166857\n",
      "[297]\tTest-logloss:0.166883\n",
      "[298]\tTest-logloss:0.16689\n",
      "[299]\tTest-logloss:0.166891\n",
      "[300]\tTest-logloss:0.166891\n",
      "[301]\tTest-logloss:0.166928\n",
      "[302]\tTest-logloss:0.166868\n",
      "[303]\tTest-logloss:0.16687\n",
      "[304]\tTest-logloss:0.166853\n",
      "[305]\tTest-logloss:0.166875\n",
      "[306]\tTest-logloss:0.166874\n",
      "[307]\tTest-logloss:0.166899\n",
      "[308]\tTest-logloss:0.166882\n",
      "[309]\tTest-logloss:0.16693\n",
      "[310]\tTest-logloss:0.166925\n",
      "[311]\tTest-logloss:0.166924\n",
      "[312]\tTest-logloss:0.166934\n",
      "[313]\tTest-logloss:0.166938\n",
      "[314]\tTest-logloss:0.16694\n",
      "[315]\tTest-logloss:0.166967\n",
      "[316]\tTest-logloss:0.166968\n",
      "[317]\tTest-logloss:0.167011\n",
      "[318]\tTest-logloss:0.166978\n",
      "[319]\tTest-logloss:0.166969\n",
      "[320]\tTest-logloss:0.166971\n",
      "[321]\tTest-logloss:0.166987\n",
      "[322]\tTest-logloss:0.166998\n",
      "[323]\tTest-logloss:0.166971\n",
      "[324]\tTest-logloss:0.166978\n",
      "[325]\tTest-logloss:0.166977\n",
      "[326]\tTest-logloss:0.166994\n",
      "[327]\tTest-logloss:0.167001\n",
      "[328]\tTest-logloss:0.167038\n",
      "[329]\tTest-logloss:0.167029\n",
      "[330]\tTest-logloss:0.167031\n",
      "[331]\tTest-logloss:0.167041\n",
      "[332]\tTest-logloss:0.167075\n",
      "[333]\tTest-logloss:0.167088\n",
      "[334]\tTest-logloss:0.167102\n",
      "[335]\tTest-logloss:0.167122\n",
      "[336]\tTest-logloss:0.167143\n",
      "[337]\tTest-logloss:0.167132\n",
      "[338]\tTest-logloss:0.167149\n",
      "[339]\tTest-logloss:0.167156\n",
      "[340]\tTest-logloss:0.167191\n",
      "[341]\tTest-logloss:0.1672\n",
      "[342]\tTest-logloss:0.167213\n",
      "[343]\tTest-logloss:0.167232\n",
      "[344]\tTest-logloss:0.167172\n",
      "[345]\tTest-logloss:0.167191\n",
      "[346]\tTest-logloss:0.167201\n",
      "[347]\tTest-logloss:0.167225\n",
      "[348]\tTest-logloss:0.167236\n",
      "[349]\tTest-logloss:0.167261\n",
      "[350]\tTest-logloss:0.167273\n",
      "[351]\tTest-logloss:0.16722\n",
      "[352]\tTest-logloss:0.167208\n",
      "[353]\tTest-logloss:0.167216\n",
      "[354]\tTest-logloss:0.167226\n",
      "[355]\tTest-logloss:0.167229\n",
      "[356]\tTest-logloss:0.167237\n",
      "[357]\tTest-logloss:0.167168\n",
      "[358]\tTest-logloss:0.167213\n",
      "[359]\tTest-logloss:0.16722\n",
      "[360]\tTest-logloss:0.167181\n",
      "[361]\tTest-logloss:0.16718\n",
      "[362]\tTest-logloss:0.16718\n",
      "[363]\tTest-logloss:0.167181\n",
      "[364]\tTest-logloss:0.167177\n",
      "[365]\tTest-logloss:0.167205\n",
      "[366]\tTest-logloss:0.167151\n",
      "[367]\tTest-logloss:0.167168\n",
      "[368]\tTest-logloss:0.16718\n",
      "[369]\tTest-logloss:0.167187\n",
      "[370]\tTest-logloss:0.16715\n",
      "[371]\tTest-logloss:0.167162\n",
      "[372]\tTest-logloss:0.167181\n",
      "[373]\tTest-logloss:0.167183\n",
      "[374]\tTest-logloss:0.16717\n",
      "[375]\tTest-logloss:0.167156\n",
      "[376]\tTest-logloss:0.167152\n",
      "[377]\tTest-logloss:0.167146\n",
      "[378]\tTest-logloss:0.167151\n",
      "[379]\tTest-logloss:0.167157\n",
      "[380]\tTest-logloss:0.167164\n",
      "[381]\tTest-logloss:0.167186\n",
      "[382]\tTest-logloss:0.167184\n",
      "[383]\tTest-logloss:0.167164\n",
      "[384]\tTest-logloss:0.167166\n",
      "[385]\tTest-logloss:0.167158\n",
      "[386]\tTest-logloss:0.167202\n",
      "[387]\tTest-logloss:0.167221\n",
      "[388]\tTest-logloss:0.16722\n",
      "[389]\tTest-logloss:0.167212\n",
      "[390]\tTest-logloss:0.167244\n",
      "[391]\tTest-logloss:0.167251\n",
      "[392]\tTest-logloss:0.167262\n",
      "[393]\tTest-logloss:0.16728\n",
      "[394]\tTest-logloss:0.16734\n",
      "[395]\tTest-logloss:0.167366\n",
      "[396]\tTest-logloss:0.167377\n",
      "[397]\tTest-logloss:0.167414\n",
      "[398]\tTest-logloss:0.167446\n",
      "[399]\tTest-logloss:0.167484\n",
      "[400]\tTest-logloss:0.167485\n",
      "[401]\tTest-logloss:0.167498\n",
      "[402]\tTest-logloss:0.167521\n",
      "[403]\tTest-logloss:0.167528\n",
      "[404]\tTest-logloss:0.167529\n",
      "Stopping. Best iteration:\n",
      "[304]\tTest-logloss:0.166853\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logloss: 0.17 with 305 rounds\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Logloss: {:.2f} with {} rounds\".format(\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_round = model.best_iteration+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round= boost_round\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
    " \n",
    "thresholds = np.append(thresholds, 1)\n",
    "f1_scores = 2*(precision*recall)/(precision+recall)\n",
    "plt.step(recall, precision, color='b', alpha=0.4, where='post')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold cutoff:  0.33103546500205994\n",
      "Max F1-score at cut-off :  0.5210401891252955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c88467bbe0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scrs = pd.DataFrame({'precision' : precision, 'recal' : recall, 'thresholds' : thresholds, 'f1_score':f1_scores})\n",
    "print(\"Threshold cutoff: \",scrs.loc[scrs['f1_score'] == scrs.f1_score.max(),'thresholds'].iloc[0])\n",
    "print(\"Max F1-score at cut-off : \",scrs.f1_score.max())\n",
    "scrs.plot(x='thresholds', y='f1_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_cutoff = scrs.loc[scrs['f1_score'] == scrs.f1_score.max(),'thresholds'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_data.drop(\"is_promoted\",axis=1), label=train_data['is_promoted'])\n",
    "dtest = xgb.DMatrix(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round= boost_round\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_pred(y, threshold= threshold_cutoff):\n",
    "    y_bin = [1 if y_cont > threshold else 0 for y_cont in y] # binarizing your output\n",
    "    return y_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(dtest)\n",
    "pred_new  = xgb_pred(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'employee_id': Emp_ID, 'is_promoted': pred_new}\n",
    "upload_XGB1 = pd.DataFrame(d)\n",
    "upload_XGB1.to_csv(\"upload_XGB1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
